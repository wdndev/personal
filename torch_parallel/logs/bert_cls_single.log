nohup: 忽略输入
/home/miniconda3/envs/qwen/lib/python3.8/site-packages/huggingface_hub/utils/_runtime.py:185: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'
  warnings.warn(
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at model/chinese-bert-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/miniconda3/envs/qwen/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[train] epoch: 1/10 step：1/1440 loss：1.939984
[train] epoch: 1/10 step：2/1440 loss：1.850046
[train] epoch: 1/10 step：3/1440 loss：1.816190
[train] epoch: 1/10 step：4/1440 loss：1.674917
[train] epoch: 1/10 step：5/1440 loss：1.767349
[train] epoch: 1/10 step：6/1440 loss：1.764518
[train] epoch: 1/10 step：7/1440 loss：1.665387
[train] epoch: 1/10 step：8/1440 loss：1.610841
[train] epoch: 1/10 step：9/1440 loss：1.643998
[train] epoch: 1/10 step：10/1440 loss：1.755541
[train] epoch: 1/10 step：11/1440 loss：1.526475
[train] epoch: 1/10 step：12/1440 loss：1.522776
[train] epoch: 1/10 step：13/1440 loss：1.577719
[train] epoch: 1/10 step：14/1440 loss：1.664693
[train] epoch: 1/10 step：15/1440 loss：1.569807
[train] epoch: 1/10 step：16/1440 loss：1.626790
[train] epoch: 1/10 step：17/1440 loss：1.522271
[train] epoch: 1/10 step：18/1440 loss：1.550084
[train] epoch: 1/10 step：19/1440 loss：1.519697
[train] epoch: 1/10 step：20/1440 loss：1.449444
[train] epoch: 1/10 step：21/1440 loss：1.418785
[train] epoch: 1/10 step：22/1440 loss：1.602039
[train] epoch: 1/10 step：23/1440 loss：1.496569
[train] epoch: 1/10 step：24/1440 loss：1.393760
[train] epoch: 1/10 step：25/1440 loss：1.409887
[train] epoch: 1/10 step：26/1440 loss：1.445562
[train] epoch: 1/10 step：27/1440 loss：1.477951
[train] epoch: 1/10 step：28/1440 loss：1.405355
[train] epoch: 1/10 step：29/1440 loss：1.332226
[train] epoch: 1/10 step：30/1440 loss：1.303032
[train] epoch: 1/10 step：31/1440 loss：1.323146
[train] epoch: 1/10 step：32/1440 loss：1.327867
[train] epoch: 1/10 step：33/1440 loss：1.444492
[train] epoch: 1/10 step：34/1440 loss：1.365418
[train] epoch: 1/10 step：35/1440 loss：1.537218
[train] epoch: 1/10 step：36/1440 loss：1.338825
[train] epoch: 1/10 step：37/1440 loss：1.408197
[train] epoch: 1/10 step：38/1440 loss：1.416543
[train] epoch: 1/10 step：39/1440 loss：1.334256
[train] epoch: 1/10 step：40/1440 loss：1.329514
[train] epoch: 1/10 step：41/1440 loss：1.293421
[train] epoch: 1/10 step：42/1440 loss：1.467437
[train] epoch: 1/10 step：43/1440 loss：1.400323
[train] epoch: 1/10 step：44/1440 loss：1.331700
[train] epoch: 1/10 step：45/1440 loss：1.344854
[train] epoch: 1/10 step：46/1440 loss：1.312582
[train] epoch: 1/10 step：47/1440 loss：1.276013
[train] epoch: 1/10 step：48/1440 loss：1.428197
[train] epoch: 1/10 step：49/1440 loss：1.450148
[train] epoch: 1/10 step：50/1440 loss：1.233960
[train] epoch: 1/10 step：51/1440 loss：1.326879
[train] epoch: 1/10 step：52/1440 loss：1.324372
[train] epoch: 1/10 step：53/1440 loss：1.424867
[train] epoch: 1/10 step：54/1440 loss：1.159559
[train] epoch: 1/10 step：55/1440 loss：1.366118
[train] epoch: 1/10 step：56/1440 loss：1.319503
[train] epoch: 1/10 step：57/1440 loss：1.207535
[train] epoch: 1/10 step：58/1440 loss：1.301130
[train] epoch: 1/10 step：59/1440 loss：1.395115
[train] epoch: 1/10 step：60/1440 loss：1.231958
[train] epoch: 1/10 step：61/1440 loss：1.201181
[train] epoch: 1/10 step：62/1440 loss：1.136675
[train] epoch: 1/10 step：63/1440 loss：1.319143
[train] epoch: 1/10 step：64/1440 loss：1.178762
[train] epoch: 1/10 step：65/1440 loss：1.114113
[train] epoch: 1/10 step：66/1440 loss：1.207933
[train] epoch: 1/10 step：67/1440 loss：1.227466
[train] epoch: 1/10 step：68/1440 loss：1.131161
[train] epoch: 1/10 step：69/1440 loss：1.256687
[train] epoch: 1/10 step：70/1440 loss：1.270965
[train] epoch: 1/10 step：71/1440 loss：1.163360
[train] epoch: 1/10 step：72/1440 loss：1.131046
[train] epoch: 1/10 step：73/1440 loss：1.451798
[train] epoch: 1/10 step：74/1440 loss：1.069810
[train] epoch: 1/10 step：75/1440 loss：1.387785
[train] epoch: 1/10 step：76/1440 loss：1.375731
[train] epoch: 1/10 step：77/1440 loss：1.254107
[train] epoch: 1/10 step：78/1440 loss：1.274124
[train] epoch: 1/10 step：79/1440 loss：1.251790
[train] epoch: 1/10 step：80/1440 loss：1.277237
[train] epoch: 1/10 step：81/1440 loss：1.092721
[train] epoch: 1/10 step：82/1440 loss：1.210829
[train] epoch: 1/10 step：83/1440 loss：1.202776
[train] epoch: 1/10 step：84/1440 loss：1.098755
[train] epoch: 1/10 step：85/1440 loss：1.234967
[train] epoch: 1/10 step：86/1440 loss：1.316170
[train] epoch: 1/10 step：87/1440 loss：1.412733
[train] epoch: 1/10 step：88/1440 loss：1.212401
[train] epoch: 1/10 step：89/1440 loss：1.072140
[train] epoch: 1/10 step：90/1440 loss：0.975899
[train] epoch: 1/10 step：91/1440 loss：1.060181
[train] epoch: 1/10 step：92/1440 loss：1.178588
[train] epoch: 1/10 step：93/1440 loss：1.184056
[train] epoch: 1/10 step：94/1440 loss：1.216061
[train] epoch: 1/10 step：95/1440 loss：1.202107
[train] epoch: 1/10 step：96/1440 loss：1.046483
[train] epoch: 1/10 step：97/1440 loss：1.039040
[train] epoch: 1/10 step：98/1440 loss：1.139025
[train] epoch: 1/10 step：99/1440 loss：1.111004
[train] epoch: 1/10 step：100/1440 loss：1.369647
[train] epoch: 1/10 step：101/1440 loss：1.362317
[train] epoch: 1/10 step：102/1440 loss：1.012951
[train] epoch: 1/10 step：103/1440 loss：1.179317
[train] epoch: 1/10 step：104/1440 loss：1.254946
[train] epoch: 1/10 step：105/1440 loss：1.054324
[train] epoch: 1/10 step：106/1440 loss：1.128809
[train] epoch: 1/10 step：107/1440 loss：1.131173
[train] epoch: 1/10 step：108/1440 loss：1.074675
[train] epoch: 1/10 step：109/1440 loss：1.147172
[train] epoch: 1/10 step：110/1440 loss：1.196097
[train] epoch: 1/10 step：111/1440 loss：1.277961
[train] epoch: 1/10 step：112/1440 loss：1.060401
[train] epoch: 1/10 step：113/1440 loss：1.330882
[train] epoch: 1/10 step：114/1440 loss：1.218273
[train] epoch: 1/10 step：115/1440 loss：1.305969
[train] epoch: 1/10 step：116/1440 loss：1.239948
[train] epoch: 1/10 step：117/1440 loss：0.926913
[train] epoch: 1/10 step：118/1440 loss：1.045383
[train] epoch: 1/10 step：119/1440 loss：1.027788
[train] epoch: 1/10 step：120/1440 loss：1.205777
[train] epoch: 1/10 step：121/1440 loss：1.187526
[train] epoch: 1/10 step：122/1440 loss：1.191195
[train] epoch: 1/10 step：123/1440 loss：0.974874
[train] epoch: 1/10 step：124/1440 loss：0.991981
[train] epoch: 1/10 step：125/1440 loss：1.373268
[train] epoch: 1/10 step：126/1440 loss：1.251186
[train] epoch: 1/10 step：127/1440 loss：0.939090
[train] epoch: 1/10 step：128/1440 loss：1.081581
[train] epoch: 1/10 step：129/1440 loss：1.490246
[train] epoch: 1/10 step：130/1440 loss：1.072863
[train] epoch: 1/10 step：131/1440 loss：1.267303
[train] epoch: 1/10 step：132/1440 loss：1.298245
[train] epoch: 1/10 step：133/1440 loss：1.154342
[train] epoch: 1/10 step：134/1440 loss：1.107376
[train] epoch: 1/10 step：135/1440 loss：1.265539
[train] epoch: 1/10 step：136/1440 loss：1.215800
[train] epoch: 1/10 step：137/1440 loss：1.330881
[train] epoch: 1/10 step：138/1440 loss：1.254397
[train] epoch: 1/10 step：139/1440 loss：1.283813
[train] epoch: 1/10 step：140/1440 loss：1.241067
[train] epoch: 1/10 step：141/1440 loss：1.066332
[train] epoch: 1/10 step：142/1440 loss：1.139646
[train] epoch: 1/10 step：143/1440 loss：1.093474
[train] epoch: 1/10 step：144/1440 loss：0.982797
[train] epoch: 2/10 step：145/1440 loss：0.882095
[train] epoch: 2/10 step：146/1440 loss：1.147749
[train] epoch: 2/10 step：147/1440 loss：0.890125
[train] epoch: 2/10 step：148/1440 loss：0.956957
[train] epoch: 2/10 step：149/1440 loss：1.128155
[train] epoch: 2/10 step：150/1440 loss：1.000988
[train] epoch: 2/10 step：151/1440 loss：0.938254
[train] epoch: 2/10 step：152/1440 loss：1.006476
[train] epoch: 2/10 step：153/1440 loss：0.791222
[train] epoch: 2/10 step：154/1440 loss：0.850957
[train] epoch: 2/10 step：155/1440 loss：1.097518
[train] epoch: 2/10 step：156/1440 loss：0.954929
[train] epoch: 2/10 step：157/1440 loss：1.152806
[train] epoch: 2/10 step：158/1440 loss：0.848871
[train] epoch: 2/10 step：159/1440 loss：0.987315
[train] epoch: 2/10 step：160/1440 loss：1.002544
[train] epoch: 2/10 step：161/1440 loss：1.012732
[train] epoch: 2/10 step：162/1440 loss：0.906929
[train] epoch: 2/10 step：163/1440 loss：0.776189
[train] epoch: 2/10 step：164/1440 loss：1.155052
[train] epoch: 2/10 step：165/1440 loss：0.865448
[train] epoch: 2/10 step：166/1440 loss：0.862711
[train] epoch: 2/10 step：167/1440 loss：0.926402
[train] epoch: 2/10 step：168/1440 loss：0.961676
[train] epoch: 2/10 step：169/1440 loss：1.003666
[train] epoch: 2/10 step：170/1440 loss：0.960408
[train] epoch: 2/10 step：171/1440 loss：0.987882
[train] epoch: 2/10 step：172/1440 loss：0.775328
[train] epoch: 2/10 step：173/1440 loss：0.920465
[train] epoch: 2/10 step：174/1440 loss：0.842564
[train] epoch: 2/10 step：175/1440 loss：1.050313
[train] epoch: 2/10 step：176/1440 loss：0.910991
[train] epoch: 2/10 step：177/1440 loss：0.968071
[train] epoch: 2/10 step：178/1440 loss：0.774247
[train] epoch: 2/10 step：179/1440 loss：1.049046
[train] epoch: 2/10 step：180/1440 loss：1.023766
[train] epoch: 2/10 step：181/1440 loss：0.981061
[train] epoch: 2/10 step：182/1440 loss：1.088907
[train] epoch: 2/10 step：183/1440 loss：1.269111
[train] epoch: 2/10 step：184/1440 loss：1.145076
[train] epoch: 2/10 step：185/1440 loss：0.953483
[train] epoch: 2/10 step：186/1440 loss：1.034073
[train] epoch: 2/10 step：187/1440 loss：1.003663
[train] epoch: 2/10 step：188/1440 loss：0.966904
[train] epoch: 2/10 step：189/1440 loss：0.977729
[train] epoch: 2/10 step：190/1440 loss：0.805603
[train] epoch: 2/10 step：191/1440 loss：0.928074
[train] epoch: 2/10 step：192/1440 loss：0.907271
[train] epoch: 2/10 step：193/1440 loss：1.047606
[train] epoch: 2/10 step：194/1440 loss：0.679513
[train] epoch: 2/10 step：195/1440 loss：0.797914
[train] epoch: 2/10 step：196/1440 loss：0.843186
[train] epoch: 2/10 step：197/1440 loss：1.158465
[train] epoch: 2/10 step：198/1440 loss：0.839823
[train] epoch: 2/10 step：199/1440 loss：0.941429
[train] epoch: 2/10 step：200/1440 loss：1.043746
[train] epoch: 2/10 step：201/1440 loss：1.175796
[train] epoch: 2/10 step：202/1440 loss：1.112741
[train] epoch: 2/10 step：203/1440 loss：1.094101
[train] epoch: 2/10 step：204/1440 loss：1.033441
[train] epoch: 2/10 step：205/1440 loss：0.957915
[train] epoch: 2/10 step：206/1440 loss：0.959595
[train] epoch: 2/10 step：207/1440 loss：0.976820
[train] epoch: 2/10 step：208/1440 loss：1.011808
[train] epoch: 2/10 step：209/1440 loss：1.152815
[train] epoch: 2/10 step：210/1440 loss：0.833724
[train] epoch: 2/10 step：211/1440 loss：0.899090
[train] epoch: 2/10 step：212/1440 loss：0.967115
[train] epoch: 2/10 step：213/1440 loss：0.853689
[train] epoch: 2/10 step：214/1440 loss：0.922824
[train] epoch: 2/10 step：215/1440 loss：1.189819
[train] epoch: 2/10 step：216/1440 loss：0.924540
[train] epoch: 2/10 step：217/1440 loss：1.053502
[train] epoch: 2/10 step：218/1440 loss：1.124252
[train] epoch: 2/10 step：219/1440 loss：1.105360
[train] epoch: 2/10 step：220/1440 loss：1.023769
[train] epoch: 2/10 step：221/1440 loss：0.998530
[train] epoch: 2/10 step：222/1440 loss：1.101864
[train] epoch: 2/10 step：223/1440 loss：0.973506
[train] epoch: 2/10 step：224/1440 loss：1.050099
[train] epoch: 2/10 step：225/1440 loss：0.858738
[train] epoch: 2/10 step：226/1440 loss：0.926889
[train] epoch: 2/10 step：227/1440 loss：1.201760
[train] epoch: 2/10 step：228/1440 loss：0.790620
[train] epoch: 2/10 step：229/1440 loss：0.783832
[train] epoch: 2/10 step：230/1440 loss：1.066959
[train] epoch: 2/10 step：231/1440 loss：0.946531
[train] epoch: 2/10 step：232/1440 loss：0.850710
[train] epoch: 2/10 step：233/1440 loss：0.911680
[train] epoch: 2/10 step：234/1440 loss：0.978772
[train] epoch: 2/10 step：235/1440 loss：1.026588
[train] epoch: 2/10 step：236/1440 loss：1.111707
[train] epoch: 2/10 step：237/1440 loss：1.028379
[train] epoch: 2/10 step：238/1440 loss：1.035295
[train] epoch: 2/10 step：239/1440 loss：0.959071
[train] epoch: 2/10 step：240/1440 loss：1.032334
[train] epoch: 2/10 step：241/1440 loss：0.891057
[train] epoch: 2/10 step：242/1440 loss：0.850003
[train] epoch: 2/10 step：243/1440 loss：0.881309
[train] epoch: 2/10 step：244/1440 loss：0.889348
[train] epoch: 2/10 step：245/1440 loss：0.929817
[train] epoch: 2/10 step：246/1440 loss：0.971578
[train] epoch: 2/10 step：247/1440 loss：0.856251
[train] epoch: 2/10 step：248/1440 loss：1.173355
[train] epoch: 2/10 step：249/1440 loss：0.961582
[train] epoch: 2/10 step：250/1440 loss：1.258640
[train] epoch: 2/10 step：251/1440 loss：1.083559
[train] epoch: 2/10 step：252/1440 loss：1.085294
[train] epoch: 2/10 step：253/1440 loss：0.864647
[train] epoch: 2/10 step：254/1440 loss：0.859480
[train] epoch: 2/10 step：255/1440 loss：1.079199
[train] epoch: 2/10 step：256/1440 loss：1.153901
[train] epoch: 2/10 step：257/1440 loss：1.024382
[train] epoch: 2/10 step：258/1440 loss：0.978225
[train] epoch: 2/10 step：259/1440 loss：0.988380
[train] epoch: 2/10 step：260/1440 loss：1.043858
[train] epoch: 2/10 step：261/1440 loss：1.094471
[train] epoch: 2/10 step：262/1440 loss：1.061249
[train] epoch: 2/10 step：263/1440 loss：1.017388
[train] epoch: 2/10 step：264/1440 loss：0.883480
[train] epoch: 2/10 step：265/1440 loss：1.080832
[train] epoch: 2/10 step：266/1440 loss：0.972435
[train] epoch: 2/10 step：267/1440 loss：1.014632
[train] epoch: 2/10 step：268/1440 loss：0.882572
[train] epoch: 2/10 step：269/1440 loss：0.882937
[train] epoch: 2/10 step：270/1440 loss：0.967816
[train] epoch: 2/10 step：271/1440 loss：0.868160
[train] epoch: 2/10 step：272/1440 loss：0.955993
[train] epoch: 2/10 step：273/1440 loss：1.056612
[train] epoch: 2/10 step：274/1440 loss：1.127726
[train] epoch: 2/10 step：275/1440 loss：1.018705
[train] epoch: 2/10 step：276/1440 loss：1.158646
[train] epoch: 2/10 step：277/1440 loss：1.043787
[train] epoch: 2/10 step：278/1440 loss：0.991746
[train] epoch: 2/10 step：279/1440 loss：1.006329
[train] epoch: 2/10 step：280/1440 loss：0.973100
[train] epoch: 2/10 step：281/1440 loss：0.882356
[train] epoch: 2/10 step：282/1440 loss：1.169594
[train] epoch: 2/10 step：283/1440 loss：0.923795
[train] epoch: 2/10 step：284/1440 loss：0.995306
[train] epoch: 2/10 step：285/1440 loss：1.000488
[train] epoch: 2/10 step：286/1440 loss：1.117998
[train] epoch: 2/10 step：287/1440 loss：0.918148
[train] epoch: 2/10 step：288/1440 loss：0.829300
[train] epoch: 3/10 step：289/1440 loss：0.866444
[train] epoch: 3/10 step：290/1440 loss：0.669171
[train] epoch: 3/10 step：291/1440 loss：0.748221
[train] epoch: 3/10 step：292/1440 loss：0.777556
[train] epoch: 3/10 step：293/1440 loss：0.678943
[train] epoch: 3/10 step：294/1440 loss：0.636877
[train] epoch: 3/10 step：295/1440 loss：0.676616
[train] epoch: 3/10 step：296/1440 loss：0.620102
[train] epoch: 3/10 step：297/1440 loss：0.641417
[train] epoch: 3/10 step：298/1440 loss：0.705060
[train] epoch: 3/10 step：299/1440 loss：0.733295
[train] epoch: 3/10 step：300/1440 loss：0.846656
[train] epoch: 3/10 step：301/1440 loss：0.788838
[train] epoch: 3/10 step：302/1440 loss：0.643232
[train] epoch: 3/10 step：303/1440 loss：0.557532
[train] epoch: 3/10 step：304/1440 loss：0.851325
[train] epoch: 3/10 step：305/1440 loss：0.460947
[train] epoch: 3/10 step：306/1440 loss：0.704062
[train] epoch: 3/10 step：307/1440 loss：0.744131
[train] epoch: 3/10 step：308/1440 loss：0.811733
[train] epoch: 3/10 step：309/1440 loss：0.714427
[train] epoch: 3/10 step：310/1440 loss：0.808821
[train] epoch: 3/10 step：311/1440 loss：0.625924
[train] epoch: 3/10 step：312/1440 loss：0.748102
[train] epoch: 3/10 step：313/1440 loss：0.556755
[train] epoch: 3/10 step：314/1440 loss：0.631317
[train] epoch: 3/10 step：315/1440 loss：0.580581
[train] epoch: 3/10 step：316/1440 loss：0.692932
[train] epoch: 3/10 step：317/1440 loss：0.392701
[train] epoch: 3/10 step：318/1440 loss：0.855127
[train] epoch: 3/10 step：319/1440 loss：0.685488
[train] epoch: 3/10 step：320/1440 loss：0.528767
[train] epoch: 3/10 step：321/1440 loss：1.053507
[train] epoch: 3/10 step：322/1440 loss：0.658000
[train] epoch: 3/10 step：323/1440 loss：0.638775
[train] epoch: 3/10 step：324/1440 loss：0.727783
[train] epoch: 3/10 step：325/1440 loss：0.601453
[train] epoch: 3/10 step：326/1440 loss：0.758614
[train] epoch: 3/10 step：327/1440 loss：0.681736
[train] epoch: 3/10 step：328/1440 loss：0.502359
[train] epoch: 3/10 step：329/1440 loss：0.608731
[train] epoch: 3/10 step：330/1440 loss：0.725740
[train] epoch: 3/10 step：331/1440 loss：0.779312
[train] epoch: 3/10 step：332/1440 loss：0.515437
[train] epoch: 3/10 step：333/1440 loss：0.619989
[train] epoch: 3/10 step：334/1440 loss：0.718873
[train] epoch: 3/10 step：335/1440 loss：0.646574
[train] epoch: 3/10 step：336/1440 loss：0.862941
[train] epoch: 3/10 step：337/1440 loss：0.806250
[train] epoch: 3/10 step：338/1440 loss：0.754783
[train] epoch: 3/10 step：339/1440 loss：0.827365
[train] epoch: 3/10 step：340/1440 loss：0.747796
[train] epoch: 3/10 step：341/1440 loss：0.650579
[train] epoch: 3/10 step：342/1440 loss：0.933592
[train] epoch: 3/10 step：343/1440 loss：0.519457
[train] epoch: 3/10 step：344/1440 loss：0.759331
[train] epoch: 3/10 step：345/1440 loss：0.589649
[train] epoch: 3/10 step：346/1440 loss：0.559234
[train] epoch: 3/10 step：347/1440 loss：0.637897
[train] epoch: 3/10 step：348/1440 loss：0.872813
[train] epoch: 3/10 step：349/1440 loss：0.915866
[train] epoch: 3/10 step：350/1440 loss：0.682086
[train] epoch: 3/10 step：351/1440 loss：0.704380
[train] epoch: 3/10 step：352/1440 loss：0.665596
[train] epoch: 3/10 step：353/1440 loss：0.762598
[train] epoch: 3/10 step：354/1440 loss：0.654689
[train] epoch: 3/10 step：355/1440 loss：0.617299
[train] epoch: 3/10 step：356/1440 loss：0.880624
[train] epoch: 3/10 step：357/1440 loss：0.626142
[train] epoch: 3/10 step：358/1440 loss：0.644419
[train] epoch: 3/10 step：359/1440 loss：0.521106
[train] epoch: 3/10 step：360/1440 loss：0.736104
[train] epoch: 3/10 step：361/1440 loss：0.855392
[train] epoch: 3/10 step：362/1440 loss：0.762200
[train] epoch: 3/10 step：363/1440 loss：1.078743
[train] epoch: 3/10 step：364/1440 loss：0.732416
[train] epoch: 3/10 step：365/1440 loss：0.687549
[train] epoch: 3/10 step：366/1440 loss：0.597286
[train] epoch: 3/10 step：367/1440 loss：0.746933
[train] epoch: 3/10 step：368/1440 loss：0.654968
[train] epoch: 3/10 step：369/1440 loss：0.556322
[train] epoch: 3/10 step：370/1440 loss：0.865902
[train] epoch: 3/10 step：371/1440 loss：0.864133
[train] epoch: 3/10 step：372/1440 loss：0.799963
[train] epoch: 3/10 step：373/1440 loss：0.809482
[train] epoch: 3/10 step：374/1440 loss：0.850896
[train] epoch: 3/10 step：375/1440 loss：0.636871
[train] epoch: 3/10 step：376/1440 loss：0.588184
[train] epoch: 3/10 step：377/1440 loss：1.021961
[train] epoch: 3/10 step：378/1440 loss：0.651658
[train] epoch: 3/10 step：379/1440 loss：0.725652
[train] epoch: 3/10 step：380/1440 loss：0.680386
[train] epoch: 3/10 step：381/1440 loss：0.780453
[train] epoch: 3/10 step：382/1440 loss：0.729487
[train] epoch: 3/10 step：383/1440 loss：0.621931
[train] epoch: 3/10 step：384/1440 loss：0.622462
[train] epoch: 3/10 step：385/1440 loss：0.924396
[train] epoch: 3/10 step：386/1440 loss：0.590860
[train] epoch: 3/10 step：387/1440 loss：0.898435
[train] epoch: 3/10 step：388/1440 loss：1.024890
[train] epoch: 3/10 step：389/1440 loss：0.559789
[train] epoch: 3/10 step：390/1440 loss：0.669142
[train] epoch: 3/10 step：391/1440 loss：1.025262
[train] epoch: 3/10 step：392/1440 loss：0.686598
[train] epoch: 3/10 step：393/1440 loss：0.613458
[train] epoch: 3/10 step：394/1440 loss：0.698231
[train] epoch: 3/10 step：395/1440 loss：0.918132
[train] epoch: 3/10 step：396/1440 loss：0.743510
[train] epoch: 3/10 step：397/1440 loss：0.668785
[train] epoch: 3/10 step：398/1440 loss：0.555899
[train] epoch: 3/10 step：399/1440 loss：0.826738
[train] epoch: 3/10 step：400/1440 loss：0.826052
[train] epoch: 3/10 step：401/1440 loss：0.756003
[train] epoch: 3/10 step：402/1440 loss：0.611998
[train] epoch: 3/10 step：403/1440 loss：0.787966
[train] epoch: 3/10 step：404/1440 loss：0.770034
[train] epoch: 3/10 step：405/1440 loss：0.776506
[train] epoch: 3/10 step：406/1440 loss：0.801914
[train] epoch: 3/10 step：407/1440 loss：0.802911
[train] epoch: 3/10 step：408/1440 loss：0.715957
[train] epoch: 3/10 step：409/1440 loss：0.628129
[train] epoch: 3/10 step：410/1440 loss：0.748836
[train] epoch: 3/10 step：411/1440 loss：0.598261
[train] epoch: 3/10 step：412/1440 loss：0.595480
[train] epoch: 3/10 step：413/1440 loss：1.057265
[train] epoch: 3/10 step：414/1440 loss：0.705825
[train] epoch: 3/10 step：415/1440 loss：0.683845
[train] epoch: 3/10 step：416/1440 loss：0.704911
[train] epoch: 3/10 step：417/1440 loss：0.789803
[train] epoch: 3/10 step：418/1440 loss：0.845154
[train] epoch: 3/10 step：419/1440 loss：0.702021
[train] epoch: 3/10 step：420/1440 loss：0.798753
[train] epoch: 3/10 step：421/1440 loss：0.890846
[train] epoch: 3/10 step：422/1440 loss：0.694738
[train] epoch: 3/10 step：423/1440 loss：0.478458
[train] epoch: 3/10 step：424/1440 loss：0.573266
[train] epoch: 3/10 step：425/1440 loss：0.747860
[train] epoch: 3/10 step：426/1440 loss：0.835277
[train] epoch: 3/10 step：427/1440 loss：0.704557
[train] epoch: 3/10 step：428/1440 loss：0.551478
[train] epoch: 3/10 step：429/1440 loss：0.827329
[train] epoch: 3/10 step：430/1440 loss：0.667334
[train] epoch: 3/10 step：431/1440 loss：0.805173
[train] epoch: 3/10 step：432/1440 loss：0.630236
[train] epoch: 4/10 step：433/1440 loss：0.429688
[train] epoch: 4/10 step：434/1440 loss：0.561692
[train] epoch: 4/10 step：435/1440 loss：0.599821
[train] epoch: 4/10 step：436/1440 loss：0.443751
[train] epoch: 4/10 step：437/1440 loss：0.456414
[train] epoch: 4/10 step：438/1440 loss：0.350612
[train] epoch: 4/10 step：439/1440 loss：0.683441
[train] epoch: 4/10 step：440/1440 loss：0.726105
[train] epoch: 4/10 step：441/1440 loss：0.597949
[train] epoch: 4/10 step：442/1440 loss：0.356301
[train] epoch: 4/10 step：443/1440 loss：0.551920
[train] epoch: 4/10 step：444/1440 loss：0.448547
[train] epoch: 4/10 step：445/1440 loss：0.379049
[train] epoch: 4/10 step：446/1440 loss：0.341635
[train] epoch: 4/10 step：447/1440 loss：0.505590
[train] epoch: 4/10 step：448/1440 loss：0.311896
[train] epoch: 4/10 step：449/1440 loss：0.262210
[train] epoch: 4/10 step：450/1440 loss：0.562337
[train] epoch: 4/10 step：451/1440 loss：0.527542
[train] epoch: 4/10 step：452/1440 loss：0.471464
[train] epoch: 4/10 step：453/1440 loss：0.455061
[train] epoch: 4/10 step：454/1440 loss：0.560764
[train] epoch: 4/10 step：455/1440 loss：0.396286
[train] epoch: 4/10 step：456/1440 loss：0.425596
[train] epoch: 4/10 step：457/1440 loss：0.758243
[train] epoch: 4/10 step：458/1440 loss：0.508836
[train] epoch: 4/10 step：459/1440 loss：0.282646
[train] epoch: 4/10 step：460/1440 loss：0.467453
[train] epoch: 4/10 step：461/1440 loss：0.612824
[train] epoch: 4/10 step：462/1440 loss：0.349766
[train] epoch: 4/10 step：463/1440 loss：0.315673
[train] epoch: 4/10 step：464/1440 loss：0.427347
[train] epoch: 4/10 step：465/1440 loss：0.479958
[train] epoch: 4/10 step：466/1440 loss：0.410682
[train] epoch: 4/10 step：467/1440 loss：0.417129
[train] epoch: 4/10 step：468/1440 loss：0.478359
[train] epoch: 4/10 step：469/1440 loss：0.436503
[train] epoch: 4/10 step：470/1440 loss：0.583991
[train] epoch: 4/10 step：471/1440 loss：0.449797
[train] epoch: 4/10 step：472/1440 loss：0.522195
[train] epoch: 4/10 step：473/1440 loss：0.627877
[train] epoch: 4/10 step：474/1440 loss：0.267737
[train] epoch: 4/10 step：475/1440 loss：0.496068
[train] epoch: 4/10 step：476/1440 loss：0.435874
[train] epoch: 4/10 step：477/1440 loss：0.386647
[train] epoch: 4/10 step：478/1440 loss：0.320168
[train] epoch: 4/10 step：479/1440 loss：0.300949
[train] epoch: 4/10 step：480/1440 loss：0.531043
[train] epoch: 4/10 step：481/1440 loss：0.358101
[train] epoch: 4/10 step：482/1440 loss：0.472169
[train] epoch: 4/10 step：483/1440 loss：0.350766
[train] epoch: 4/10 step：484/1440 loss：0.527409
[train] epoch: 4/10 step：485/1440 loss：0.366801
[train] epoch: 4/10 step：486/1440 loss：0.605516
[train] epoch: 4/10 step：487/1440 loss：0.257325
[train] epoch: 4/10 step：488/1440 loss：0.762685
[train] epoch: 4/10 step：489/1440 loss：0.679903
[train] epoch: 4/10 step：490/1440 loss：0.571092
[train] epoch: 4/10 step：491/1440 loss：0.468694
[train] epoch: 4/10 step：492/1440 loss：0.396393
[train] epoch: 4/10 step：493/1440 loss：0.631925
[train] epoch: 4/10 step：494/1440 loss：0.510646
[train] epoch: 4/10 step：495/1440 loss：0.227008
[train] epoch: 4/10 step：496/1440 loss：0.515258
[train] epoch: 4/10 step：497/1440 loss：0.307349
[train] epoch: 4/10 step：498/1440 loss：0.520352
[train] epoch: 4/10 step：499/1440 loss：0.530438
[train] epoch: 4/10 step：500/1440 loss：0.367379
[train] epoch: 4/10 step：501/1440 loss：0.464321
[train] epoch: 4/10 step：502/1440 loss：0.369669
[train] epoch: 4/10 step：503/1440 loss：0.402684
[train] epoch: 4/10 step：504/1440 loss：0.650171
[train] epoch: 4/10 step：505/1440 loss：0.511952
[train] epoch: 4/10 step：506/1440 loss：0.443493
[train] epoch: 4/10 step：507/1440 loss：0.554266
[train] epoch: 4/10 step：508/1440 loss：0.573648
[train] epoch: 4/10 step：509/1440 loss：0.468441
[train] epoch: 4/10 step：510/1440 loss：0.606577
[train] epoch: 4/10 step：511/1440 loss：0.604327
[train] epoch: 4/10 step：512/1440 loss：0.888220
[train] epoch: 4/10 step：513/1440 loss：0.547551
[train] epoch: 4/10 step：514/1440 loss：0.478679
[train] epoch: 4/10 step：515/1440 loss：0.322683
[train] epoch: 4/10 step：516/1440 loss：0.649420
[train] epoch: 4/10 step：517/1440 loss：0.379947
[train] epoch: 4/10 step：518/1440 loss：0.572889
[train] epoch: 4/10 step：519/1440 loss：0.492434
[train] epoch: 4/10 step：520/1440 loss：0.434602
[train] epoch: 4/10 step：521/1440 loss：0.581908
[train] epoch: 4/10 step：522/1440 loss：0.357579
[train] epoch: 4/10 step：523/1440 loss：0.471422
[train] epoch: 4/10 step：524/1440 loss：0.265530
[train] epoch: 4/10 step：525/1440 loss：0.500935
[train] epoch: 4/10 step：526/1440 loss：0.402290
[train] epoch: 4/10 step：527/1440 loss：0.680876
[train] epoch: 4/10 step：528/1440 loss：0.482365
[train] epoch: 4/10 step：529/1440 loss：0.354211
[train] epoch: 4/10 step：530/1440 loss：0.439197
[train] epoch: 4/10 step：531/1440 loss：0.546836
[train] epoch: 4/10 step：532/1440 loss：0.307870
[train] epoch: 4/10 step：533/1440 loss：0.499200
[train] epoch: 4/10 step：534/1440 loss：0.658334
[train] epoch: 4/10 step：535/1440 loss：0.414490
[train] epoch: 4/10 step：536/1440 loss：0.565199
[train] epoch: 4/10 step：537/1440 loss：0.456780
[train] epoch: 4/10 step：538/1440 loss：0.529628
[train] epoch: 4/10 step：539/1440 loss：0.503489
[train] epoch: 4/10 step：540/1440 loss：0.524612
[train] epoch: 4/10 step：541/1440 loss：0.742786
[train] epoch: 4/10 step：542/1440 loss：0.358447
[train] epoch: 4/10 step：543/1440 loss：0.340820
[train] epoch: 4/10 step：544/1440 loss：0.478095
[train] epoch: 4/10 step：545/1440 loss：0.435739
[train] epoch: 4/10 step：546/1440 loss：0.709285
[train] epoch: 4/10 step：547/1440 loss：0.663706
[train] epoch: 4/10 step：548/1440 loss：0.722545
[train] epoch: 4/10 step：549/1440 loss：0.455890
[train] epoch: 4/10 step：550/1440 loss：0.440167
[train] epoch: 4/10 step：551/1440 loss：0.635640
[train] epoch: 4/10 step：552/1440 loss：0.727749
[train] epoch: 4/10 step：553/1440 loss：0.620696
[train] epoch: 4/10 step：554/1440 loss：0.545473
[train] epoch: 4/10 step：555/1440 loss：0.443845
[train] epoch: 4/10 step：556/1440 loss：0.587624
[train] epoch: 4/10 step：557/1440 loss：0.466845
[train] epoch: 4/10 step：558/1440 loss：0.567017
[train] epoch: 4/10 step：559/1440 loss：0.450111
[train] epoch: 4/10 step：560/1440 loss：0.600985
[train] epoch: 4/10 step：561/1440 loss：0.566808
[train] epoch: 4/10 step：562/1440 loss：0.555501
[train] epoch: 4/10 step：563/1440 loss：0.605520
[train] epoch: 4/10 step：564/1440 loss：0.528952
[train] epoch: 4/10 step：565/1440 loss：0.602512
[train] epoch: 4/10 step：566/1440 loss：0.554981
[train] epoch: 4/10 step：567/1440 loss：0.558315
[train] epoch: 4/10 step：568/1440 loss：0.766183
[train] epoch: 4/10 step：569/1440 loss：0.541219
[train] epoch: 4/10 step：570/1440 loss：0.327508
[train] epoch: 4/10 step：571/1440 loss：0.340541
[train] epoch: 4/10 step：572/1440 loss：0.602317
[train] epoch: 4/10 step：573/1440 loss：0.457686
[train] epoch: 4/10 step：574/1440 loss：0.545305
[train] epoch: 4/10 step：575/1440 loss：0.534532
[train] epoch: 4/10 step：576/1440 loss：0.656150
[train] epoch: 5/10 step：577/1440 loss：0.346440
[train] epoch: 5/10 step：578/1440 loss：0.335448
[train] epoch: 5/10 step：579/1440 loss：0.372302
[train] epoch: 5/10 step：580/1440 loss：0.345884
[train] epoch: 5/10 step：581/1440 loss：0.317375
[train] epoch: 5/10 step：582/1440 loss：0.284675
[train] epoch: 5/10 step：583/1440 loss：0.224543
[train] epoch: 5/10 step：584/1440 loss：0.363390
[train] epoch: 5/10 step：585/1440 loss：0.333569
[train] epoch: 5/10 step：586/1440 loss：0.512160
[train] epoch: 5/10 step：587/1440 loss：0.417899
[train] epoch: 5/10 step：588/1440 loss：0.285453
[train] epoch: 5/10 step：589/1440 loss：0.463731
[train] epoch: 5/10 step：590/1440 loss：0.218975
[train] epoch: 5/10 step：591/1440 loss：0.534923
[train] epoch: 5/10 step：592/1440 loss：0.263577
[train] epoch: 5/10 step：593/1440 loss：0.388840
[train] epoch: 5/10 step：594/1440 loss：0.206903
[train] epoch: 5/10 step：595/1440 loss：0.222713
[train] epoch: 5/10 step：596/1440 loss：0.364301
[train] epoch: 5/10 step：597/1440 loss：0.184852
[train] epoch: 5/10 step：598/1440 loss：0.359100
[train] epoch: 5/10 step：599/1440 loss：0.258532
[train] epoch: 5/10 step：600/1440 loss：0.211643
[train] epoch: 5/10 step：601/1440 loss：0.307936
[train] epoch: 5/10 step：602/1440 loss：0.232721
[train] epoch: 5/10 step：603/1440 loss：0.322365
[train] epoch: 5/10 step：604/1440 loss：0.318546
[train] epoch: 5/10 step：605/1440 loss：0.417312
[train] epoch: 5/10 step：606/1440 loss：0.299796
[train] epoch: 5/10 step：607/1440 loss：0.464534
[train] epoch: 5/10 step：608/1440 loss：0.397636
[train] epoch: 5/10 step：609/1440 loss：0.242395
[train] epoch: 5/10 step：610/1440 loss：0.390655
[train] epoch: 5/10 step：611/1440 loss：0.373738
[train] epoch: 5/10 step：612/1440 loss：0.258617
[train] epoch: 5/10 step：613/1440 loss：0.398930
[train] epoch: 5/10 step：614/1440 loss：0.371608
[train] epoch: 5/10 step：615/1440 loss：0.260963
[train] epoch: 5/10 step：616/1440 loss：0.342917
[train] epoch: 5/10 step：617/1440 loss：0.242593
[train] epoch: 5/10 step：618/1440 loss：0.313810
[train] epoch: 5/10 step：619/1440 loss：0.301912
[train] epoch: 5/10 step：620/1440 loss：0.172998
[train] epoch: 5/10 step：621/1440 loss：0.226047
[train] epoch: 5/10 step：622/1440 loss：0.298859
[train] epoch: 5/10 step：623/1440 loss：0.438522
[train] epoch: 5/10 step：624/1440 loss：0.344220
[train] epoch: 5/10 step：625/1440 loss：0.377562
[train] epoch: 5/10 step：626/1440 loss：0.602565
[train] epoch: 5/10 step：627/1440 loss：0.390795
[train] epoch: 5/10 step：628/1440 loss：0.380235
[train] epoch: 5/10 step：629/1440 loss：0.295096
[train] epoch: 5/10 step：630/1440 loss：0.299158
[train] epoch: 5/10 step：631/1440 loss：0.328051
[train] epoch: 5/10 step：632/1440 loss：0.214125
[train] epoch: 5/10 step：633/1440 loss：0.166414
[train] epoch: 5/10 step：634/1440 loss：0.395254
[train] epoch: 5/10 step：635/1440 loss：0.245748
[train] epoch: 5/10 step：636/1440 loss：0.434979
[train] epoch: 5/10 step：637/1440 loss：0.234580
[train] epoch: 5/10 step：638/1440 loss：0.202541
[train] epoch: 5/10 step：639/1440 loss：0.348358
[train] epoch: 5/10 step：640/1440 loss：0.191541
[train] epoch: 5/10 step：641/1440 loss：0.206549
[train] epoch: 5/10 step：642/1440 loss：0.560774
[train] epoch: 5/10 step：643/1440 loss：0.332644
[train] epoch: 5/10 step：644/1440 loss：0.236670
[train] epoch: 5/10 step：645/1440 loss：0.258915
[train] epoch: 5/10 step：646/1440 loss：0.512091
[train] epoch: 5/10 step：647/1440 loss：0.372289
[train] epoch: 5/10 step：648/1440 loss：0.314178
[train] epoch: 5/10 step：649/1440 loss：0.287435
[train] epoch: 5/10 step：650/1440 loss：0.336216
[train] epoch: 5/10 step：651/1440 loss：0.423059
[train] epoch: 5/10 step：652/1440 loss：0.371502
[train] epoch: 5/10 step：653/1440 loss：0.272318
[train] epoch: 5/10 step：654/1440 loss：0.301038
[train] epoch: 5/10 step：655/1440 loss：0.257720
[train] epoch: 5/10 step：656/1440 loss：0.544595
[train] epoch: 5/10 step：657/1440 loss：0.529289
[train] epoch: 5/10 step：658/1440 loss：0.285671
[train] epoch: 5/10 step：659/1440 loss：0.276581
[train] epoch: 5/10 step：660/1440 loss：0.484093
[train] epoch: 5/10 step：661/1440 loss：0.298032
[train] epoch: 5/10 step：662/1440 loss：0.454479
[train] epoch: 5/10 step：663/1440 loss：0.324197
[train] epoch: 5/10 step：664/1440 loss：0.224307
[train] epoch: 5/10 step：665/1440 loss：0.399288
[train] epoch: 5/10 step：666/1440 loss：0.292487
[train] epoch: 5/10 step：667/1440 loss：0.458006
[train] epoch: 5/10 step：668/1440 loss：0.300196
[train] epoch: 5/10 step：669/1440 loss：0.287657
[train] epoch: 5/10 step：670/1440 loss：0.319915
[train] epoch: 5/10 step：671/1440 loss：0.363507
[train] epoch: 5/10 step：672/1440 loss：0.335834
[train] epoch: 5/10 step：673/1440 loss：0.264911
[train] epoch: 5/10 step：674/1440 loss：0.418364
[train] epoch: 5/10 step：675/1440 loss：0.473766
[train] epoch: 5/10 step：676/1440 loss：0.460118
[train] epoch: 5/10 step：677/1440 loss：0.392557
[train] epoch: 5/10 step：678/1440 loss：0.470406
[train] epoch: 5/10 step：679/1440 loss：0.364194
[train] epoch: 5/10 step：680/1440 loss：0.333648
[train] epoch: 5/10 step：681/1440 loss：0.299253
[train] epoch: 5/10 step：682/1440 loss：0.411112
[train] epoch: 5/10 step：683/1440 loss：0.316547
[train] epoch: 5/10 step：684/1440 loss：0.475695
[train] epoch: 5/10 step：685/1440 loss：0.492314
[train] epoch: 5/10 step：686/1440 loss：0.344606
[train] epoch: 5/10 step：687/1440 loss：0.331962
[train] epoch: 5/10 step：688/1440 loss：0.548997
[train] epoch: 5/10 step：689/1440 loss：0.357619
[train] epoch: 5/10 step：690/1440 loss：0.367462
[train] epoch: 5/10 step：691/1440 loss：0.445299
[train] epoch: 5/10 step：692/1440 loss：0.328618
[train] epoch: 5/10 step：693/1440 loss：0.152675
[train] epoch: 5/10 step：694/1440 loss：0.559274
[train] epoch: 5/10 step：695/1440 loss：0.392576
[train] epoch: 5/10 step：696/1440 loss：0.263759
[train] epoch: 5/10 step：697/1440 loss：0.245404
[train] epoch: 5/10 step：698/1440 loss：0.251571
[train] epoch: 5/10 step：699/1440 loss：0.355133
[train] epoch: 5/10 step：700/1440 loss：0.306618
[train] epoch: 5/10 step：701/1440 loss：0.407153
[train] epoch: 5/10 step：702/1440 loss：0.451897
[train] epoch: 5/10 step：703/1440 loss：0.208653
[train] epoch: 5/10 step：704/1440 loss：0.209141
[train] epoch: 5/10 step：705/1440 loss：0.296517
[train] epoch: 5/10 step：706/1440 loss：0.357174
[train] epoch: 5/10 step：707/1440 loss：0.293127
[train] epoch: 5/10 step：708/1440 loss：0.261337
[train] epoch: 5/10 step：709/1440 loss：0.279212
[train] epoch: 5/10 step：710/1440 loss：0.426704
[train] epoch: 5/10 step：711/1440 loss：0.448833
[train] epoch: 5/10 step：712/1440 loss：0.194434
[train] epoch: 5/10 step：713/1440 loss：0.323561
[train] epoch: 5/10 step：714/1440 loss：0.455000
[train] epoch: 5/10 step：715/1440 loss：0.522253
[train] epoch: 5/10 step：716/1440 loss：0.388043
[train] epoch: 5/10 step：717/1440 loss：0.341892
[train] epoch: 5/10 step：718/1440 loss：0.359551
[train] epoch: 5/10 step：719/1440 loss：0.467396
[train] epoch: 5/10 step：720/1440 loss：0.387115
[train] epoch: 6/10 step：721/1440 loss：0.169280
[train] epoch: 6/10 step：722/1440 loss：0.221226
[train] epoch: 6/10 step：723/1440 loss：0.125204
[train] epoch: 6/10 step：724/1440 loss：0.150668
[train] epoch: 6/10 step：725/1440 loss：0.310326
[train] epoch: 6/10 step：726/1440 loss：0.097794
[train] epoch: 6/10 step：727/1440 loss：0.181936
[train] epoch: 6/10 step：728/1440 loss：0.072008
[train] epoch: 6/10 step：729/1440 loss：0.217890
[train] epoch: 6/10 step：730/1440 loss：0.160883
[train] epoch: 6/10 step：731/1440 loss：0.132982
[train] epoch: 6/10 step：732/1440 loss：0.196098
[train] epoch: 6/10 step：733/1440 loss：0.288828
[train] epoch: 6/10 step：734/1440 loss：0.169264
[train] epoch: 6/10 step：735/1440 loss：0.210732
[train] epoch: 6/10 step：736/1440 loss：0.435654
[train] epoch: 6/10 step：737/1440 loss：0.325867
[train] epoch: 6/10 step：738/1440 loss：0.197410
[train] epoch: 6/10 step：739/1440 loss：0.337011
[train] epoch: 6/10 step：740/1440 loss：0.375515
[train] epoch: 6/10 step：741/1440 loss：0.143228
[train] epoch: 6/10 step：742/1440 loss：0.217063
[train] epoch: 6/10 step：743/1440 loss：0.211221
[train] epoch: 6/10 step：744/1440 loss：0.181546
[train] epoch: 6/10 step：745/1440 loss：0.288606
[train] epoch: 6/10 step：746/1440 loss：0.199557
[train] epoch: 6/10 step：747/1440 loss：0.231512
[train] epoch: 6/10 step：748/1440 loss：0.289403
[train] epoch: 6/10 step：749/1440 loss：0.252728
[train] epoch: 6/10 step：750/1440 loss：0.159063
[train] epoch: 6/10 step：751/1440 loss：0.210037
[train] epoch: 6/10 step：752/1440 loss：0.143578
[train] epoch: 6/10 step：753/1440 loss：0.075895
[train] epoch: 6/10 step：754/1440 loss：0.343195
[train] epoch: 6/10 step：755/1440 loss：0.412786
[train] epoch: 6/10 step：756/1440 loss：0.188770
[train] epoch: 6/10 step：757/1440 loss：0.304393
[train] epoch: 6/10 step：758/1440 loss：0.235660
[train] epoch: 6/10 step：759/1440 loss：0.121954
[train] epoch: 6/10 step：760/1440 loss：0.144421
[train] epoch: 6/10 step：761/1440 loss：0.133076
[train] epoch: 6/10 step：762/1440 loss：0.186775
[train] epoch: 6/10 step：763/1440 loss：0.183613
[train] epoch: 6/10 step：764/1440 loss：0.154475
[train] epoch: 6/10 step：765/1440 loss：0.140788
[train] epoch: 6/10 step：766/1440 loss：0.136049
[train] epoch: 6/10 step：767/1440 loss：0.279928
[train] epoch: 6/10 step：768/1440 loss：0.126156
[train] epoch: 6/10 step：769/1440 loss：0.162895
[train] epoch: 6/10 step：770/1440 loss：0.137268
[train] epoch: 6/10 step：771/1440 loss：0.100008
[train] epoch: 6/10 step：772/1440 loss：0.129268
[train] epoch: 6/10 step：773/1440 loss：0.346277
[train] epoch: 6/10 step：774/1440 loss：0.268340
[train] epoch: 6/10 step：775/1440 loss：0.421279
[train] epoch: 6/10 step：776/1440 loss：0.233128
[train] epoch: 6/10 step：777/1440 loss：0.228635
[train] epoch: 6/10 step：778/1440 loss：0.203538
[train] epoch: 6/10 step：779/1440 loss：0.347299
[train] epoch: 6/10 step：780/1440 loss：0.234208
[train] epoch: 6/10 step：781/1440 loss：0.263622
[train] epoch: 6/10 step：782/1440 loss：0.277371
[train] epoch: 6/10 step：783/1440 loss：0.325460
[train] epoch: 6/10 step：784/1440 loss：0.271389
[train] epoch: 6/10 step：785/1440 loss：0.203231
[train] epoch: 6/10 step：786/1440 loss：0.119059
[train] epoch: 6/10 step：787/1440 loss：0.163640
[train] epoch: 6/10 step：788/1440 loss：0.243345
[train] epoch: 6/10 step：789/1440 loss：0.116738
[train] epoch: 6/10 step：790/1440 loss：0.114689
[train] epoch: 6/10 step：791/1440 loss：0.215362
[train] epoch: 6/10 step：792/1440 loss：0.190781
[train] epoch: 6/10 step：793/1440 loss：0.321525
[train] epoch: 6/10 step：794/1440 loss：0.269925
[train] epoch: 6/10 step：795/1440 loss：0.166087
[train] epoch: 6/10 step：796/1440 loss：0.214923
[train] epoch: 6/10 step：797/1440 loss：0.277858
[train] epoch: 6/10 step：798/1440 loss：0.236351
[train] epoch: 6/10 step：799/1440 loss：0.157685
[train] epoch: 6/10 step：800/1440 loss：0.192508
[train] epoch: 6/10 step：801/1440 loss：0.114693
[train] epoch: 6/10 step：802/1440 loss：0.239802
[train] epoch: 6/10 step：803/1440 loss：0.249972
[train] epoch: 6/10 step：804/1440 loss：0.235148
[train] epoch: 6/10 step：805/1440 loss：0.307562
[train] epoch: 6/10 step：806/1440 loss：0.310202
[train] epoch: 6/10 step：807/1440 loss：0.320394
[train] epoch: 6/10 step：808/1440 loss：0.251104
[train] epoch: 6/10 step：809/1440 loss：0.333346
[train] epoch: 6/10 step：810/1440 loss：0.300879
[train] epoch: 6/10 step：811/1440 loss：0.362304
[train] epoch: 6/10 step：812/1440 loss：0.281671
[train] epoch: 6/10 step：813/1440 loss：0.183631
[train] epoch: 6/10 step：814/1440 loss：0.137141
[train] epoch: 6/10 step：815/1440 loss：0.288386
[train] epoch: 6/10 step：816/1440 loss：0.185914
[train] epoch: 6/10 step：817/1440 loss：0.274881
[train] epoch: 6/10 step：818/1440 loss：0.284529
[train] epoch: 6/10 step：819/1440 loss：0.125097
[train] epoch: 6/10 step：820/1440 loss：0.291202
[train] epoch: 6/10 step：821/1440 loss：0.175381
[train] epoch: 6/10 step：822/1440 loss：0.115506
[train] epoch: 6/10 step：823/1440 loss：0.195928
[train] epoch: 6/10 step：824/1440 loss：0.175227
[train] epoch: 6/10 step：825/1440 loss：0.329308
[train] epoch: 6/10 step：826/1440 loss：0.315856
[train] epoch: 6/10 step：827/1440 loss：0.230516
[train] epoch: 6/10 step：828/1440 loss：0.291227
[train] epoch: 6/10 step：829/1440 loss：0.292870
[train] epoch: 6/10 step：830/1440 loss：0.236921
[train] epoch: 6/10 step：831/1440 loss：0.461432
[train] epoch: 6/10 step：832/1440 loss：0.135872
[train] epoch: 6/10 step：833/1440 loss：0.115414
[train] epoch: 6/10 step：834/1440 loss：0.161220
[train] epoch: 6/10 step：835/1440 loss：0.166365
[train] epoch: 6/10 step：836/1440 loss：0.331672
[train] epoch: 6/10 step：837/1440 loss：0.292182
[train] epoch: 6/10 step：838/1440 loss：0.249621
[train] epoch: 6/10 step：839/1440 loss：0.239915
[train] epoch: 6/10 step：840/1440 loss：0.152911
[train] epoch: 6/10 step：841/1440 loss：0.256130
[train] epoch: 6/10 step：842/1440 loss：0.195223
[train] epoch: 6/10 step：843/1440 loss：0.309044
[train] epoch: 6/10 step：844/1440 loss：0.249390
[train] epoch: 6/10 step：845/1440 loss：0.399427
[train] epoch: 6/10 step：846/1440 loss：0.141189
[train] epoch: 6/10 step：847/1440 loss：0.238608
[train] epoch: 6/10 step：848/1440 loss：0.174174
[train] epoch: 6/10 step：849/1440 loss：0.215234
[train] epoch: 6/10 step：850/1440 loss：0.258022
[train] epoch: 6/10 step：851/1440 loss：0.252558
[train] epoch: 6/10 step：852/1440 loss：0.292715
[train] epoch: 6/10 step：853/1440 loss：0.341463
[train] epoch: 6/10 step：854/1440 loss：0.264656
[train] epoch: 6/10 step：855/1440 loss：0.179985
[train] epoch: 6/10 step：856/1440 loss：0.344058
[train] epoch: 6/10 step：857/1440 loss：0.112503
[train] epoch: 6/10 step：858/1440 loss：0.253036
[train] epoch: 6/10 step：859/1440 loss：0.255629
[train] epoch: 6/10 step：860/1440 loss：0.233265
[train] epoch: 6/10 step：861/1440 loss：0.364067
[train] epoch: 6/10 step：862/1440 loss：0.204353
[train] epoch: 6/10 step：863/1440 loss：0.282312
[train] epoch: 6/10 step：864/1440 loss：0.322238
[train] epoch: 7/10 step：865/1440 loss：0.231300
[train] epoch: 7/10 step：866/1440 loss：0.234635
[train] epoch: 7/10 step：867/1440 loss：0.173865
[train] epoch: 7/10 step：868/1440 loss：0.213591
[train] epoch: 7/10 step：869/1440 loss：0.299839
[train] epoch: 7/10 step：870/1440 loss：0.156732
[train] epoch: 7/10 step：871/1440 loss：0.189917
[train] epoch: 7/10 step：872/1440 loss：0.079648
[train] epoch: 7/10 step：873/1440 loss：0.064506
[train] epoch: 7/10 step：874/1440 loss：0.200095
[train] epoch: 7/10 step：875/1440 loss：0.054366
[train] epoch: 7/10 step：876/1440 loss：0.157567
[train] epoch: 7/10 step：877/1440 loss：0.063245
[train] epoch: 7/10 step：878/1440 loss：0.091117
[train] epoch: 7/10 step：879/1440 loss：0.218910
[train] epoch: 7/10 step：880/1440 loss：0.048033
[train] epoch: 7/10 step：881/1440 loss：0.102845
[train] epoch: 7/10 step：882/1440 loss：0.099233
[train] epoch: 7/10 step：883/1440 loss：0.126740
[train] epoch: 7/10 step：884/1440 loss：0.180877
[train] epoch: 7/10 step：885/1440 loss：0.261167
[train] epoch: 7/10 step：886/1440 loss：0.180649
[train] epoch: 7/10 step：887/1440 loss：0.120860
[train] epoch: 7/10 step：888/1440 loss：0.255772
[train] epoch: 7/10 step：889/1440 loss：0.074939
[train] epoch: 7/10 step：890/1440 loss：0.223218
[train] epoch: 7/10 step：891/1440 loss：0.138050
[train] epoch: 7/10 step：892/1440 loss：0.116355
[train] epoch: 7/10 step：893/1440 loss：0.170162
[train] epoch: 7/10 step：894/1440 loss：0.216200
[train] epoch: 7/10 step：895/1440 loss：0.182902
[train] epoch: 7/10 step：896/1440 loss：0.345493
[train] epoch: 7/10 step：897/1440 loss：0.150145
[train] epoch: 7/10 step：898/1440 loss：0.195263
[train] epoch: 7/10 step：899/1440 loss：0.127355
[train] epoch: 7/10 step：900/1440 loss：0.101601
[train] epoch: 7/10 step：901/1440 loss：0.136347
[train] epoch: 7/10 step：902/1440 loss：0.171218
[train] epoch: 7/10 step：903/1440 loss：0.165245
[train] epoch: 7/10 step：904/1440 loss：0.124194
[train] epoch: 7/10 step：905/1440 loss：0.223181
[train] epoch: 7/10 step：906/1440 loss：0.173782
[train] epoch: 7/10 step：907/1440 loss：0.187109
[train] epoch: 7/10 step：908/1440 loss：0.095331
[train] epoch: 7/10 step：909/1440 loss：0.117611
[train] epoch: 7/10 step：910/1440 loss：0.089971
[train] epoch: 7/10 step：911/1440 loss：0.069118
[train] epoch: 7/10 step：912/1440 loss：0.119101
[train] epoch: 7/10 step：913/1440 loss：0.043859
[train] epoch: 7/10 step：914/1440 loss：0.060520
[train] epoch: 7/10 step：915/1440 loss：0.160207
[train] epoch: 7/10 step：916/1440 loss：0.118548
[train] epoch: 7/10 step：917/1440 loss：0.093131
[train] epoch: 7/10 step：918/1440 loss：0.276342
[train] epoch: 7/10 step：919/1440 loss：0.095722
[train] epoch: 7/10 step：920/1440 loss：0.263603
[train] epoch: 7/10 step：921/1440 loss：0.052784
[train] epoch: 7/10 step：922/1440 loss：0.149426
[train] epoch: 7/10 step：923/1440 loss：0.016504
[train] epoch: 7/10 step：924/1440 loss：0.099865
[train] epoch: 7/10 step：925/1440 loss：0.129657
[train] epoch: 7/10 step：926/1440 loss：0.068313
[train] epoch: 7/10 step：927/1440 loss：0.068117
[train] epoch: 7/10 step：928/1440 loss：0.242963
[train] epoch: 7/10 step：929/1440 loss：0.045934
[train] epoch: 7/10 step：930/1440 loss：0.177111
[train] epoch: 7/10 step：931/1440 loss：0.118045
[train] epoch: 7/10 step：932/1440 loss：0.084463
[train] epoch: 7/10 step：933/1440 loss：0.238606
[train] epoch: 7/10 step：934/1440 loss：0.036167
[train] epoch: 7/10 step：935/1440 loss：0.121859
[train] epoch: 7/10 step：936/1440 loss：0.219148
[train] epoch: 7/10 step：937/1440 loss：0.139454
[train] epoch: 7/10 step：938/1440 loss：0.038377
[train] epoch: 7/10 step：939/1440 loss：0.131157
[train] epoch: 7/10 step：940/1440 loss：0.150290
[train] epoch: 7/10 step：941/1440 loss：0.039434
[train] epoch: 7/10 step：942/1440 loss：0.196461
[train] epoch: 7/10 step：943/1440 loss：0.063533
[train] epoch: 7/10 step：944/1440 loss：0.273422
[train] epoch: 7/10 step：945/1440 loss：0.172468
[train] epoch: 7/10 step：946/1440 loss：0.069175
[train] epoch: 7/10 step：947/1440 loss：0.169974
[train] epoch: 7/10 step：948/1440 loss：0.244704
[train] epoch: 7/10 step：949/1440 loss：0.236585
[train] epoch: 7/10 step：950/1440 loss：0.125213
[train] epoch: 7/10 step：951/1440 loss：0.217459
[train] epoch: 7/10 step：952/1440 loss：0.196803
[train] epoch: 7/10 step：953/1440 loss：0.176811
[train] epoch: 7/10 step：954/1440 loss：0.167371
[train] epoch: 7/10 step：955/1440 loss：0.213675
[train] epoch: 7/10 step：956/1440 loss：0.243668
[train] epoch: 7/10 step：957/1440 loss：0.200489
[train] epoch: 7/10 step：958/1440 loss：0.128973
[train] epoch: 7/10 step：959/1440 loss：0.231815
[train] epoch: 7/10 step：960/1440 loss：0.238139
[train] epoch: 7/10 step：961/1440 loss：0.136906
[train] epoch: 7/10 step：962/1440 loss：0.271231
[train] epoch: 7/10 step：963/1440 loss：0.227530
[train] epoch: 7/10 step：964/1440 loss：0.238879
[train] epoch: 7/10 step：965/1440 loss：0.116743
[train] epoch: 7/10 step：966/1440 loss：0.127773
[train] epoch: 7/10 step：967/1440 loss：0.175310
[train] epoch: 7/10 step：968/1440 loss：0.298876
[train] epoch: 7/10 step：969/1440 loss：0.154190
[train] epoch: 7/10 step：970/1440 loss：0.205674
[train] epoch: 7/10 step：971/1440 loss：0.113459
[train] epoch: 7/10 step：972/1440 loss：0.061923
[train] epoch: 7/10 step：973/1440 loss：0.220495
[train] epoch: 7/10 step：974/1440 loss：0.102298
[train] epoch: 7/10 step：975/1440 loss：0.042807
[train] epoch: 7/10 step：976/1440 loss：0.162178
[train] epoch: 7/10 step：977/1440 loss：0.058377
[train] epoch: 7/10 step：978/1440 loss：0.040332
[train] epoch: 7/10 step：979/1440 loss：0.193662
[train] epoch: 7/10 step：980/1440 loss：0.069816
[train] epoch: 7/10 step：981/1440 loss：0.057161
[train] epoch: 7/10 step：982/1440 loss：0.512646
[train] epoch: 7/10 step：983/1440 loss：0.192300
[train] epoch: 7/10 step：984/1440 loss：0.037021
[train] epoch: 7/10 step：985/1440 loss：0.207668
[train] epoch: 7/10 step：986/1440 loss：0.072741
[train] epoch: 7/10 step：987/1440 loss：0.121012
[train] epoch: 7/10 step：988/1440 loss：0.239968
[train] epoch: 7/10 step：989/1440 loss：0.161655
[train] epoch: 7/10 step：990/1440 loss：0.197994
[train] epoch: 7/10 step：991/1440 loss：0.175417
[train] epoch: 7/10 step：992/1440 loss：0.175615
[train] epoch: 7/10 step：993/1440 loss：0.127578
[train] epoch: 7/10 step：994/1440 loss：0.058374
[train] epoch: 7/10 step：995/1440 loss：0.160506
[train] epoch: 7/10 step：996/1440 loss：0.463353
[train] epoch: 7/10 step：997/1440 loss：0.352781
[train] epoch: 7/10 step：998/1440 loss：0.090912
[train] epoch: 7/10 step：999/1440 loss：0.071776
[train] epoch: 7/10 step：1000/1440 loss：0.249390
[train] epoch: 7/10 step：1001/1440 loss：0.213281
[train] epoch: 7/10 step：1002/1440 loss：0.230035
[train] epoch: 7/10 step：1003/1440 loss：0.319268
[train] epoch: 7/10 step：1004/1440 loss：0.271219
[train] epoch: 7/10 step：1005/1440 loss：0.135219
[train] epoch: 7/10 step：1006/1440 loss：0.092065
[train] epoch: 7/10 step：1007/1440 loss：0.157472
[train] epoch: 7/10 step：1008/1440 loss：0.167915
[train] epoch: 8/10 step：1009/1440 loss：0.209490
[train] epoch: 8/10 step：1010/1440 loss：0.187368
[train] epoch: 8/10 step：1011/1440 loss：0.177359
[train] epoch: 8/10 step：1012/1440 loss：0.137654
[train] epoch: 8/10 step：1013/1440 loss：0.075847
[train] epoch: 8/10 step：1014/1440 loss：0.081270
[train] epoch: 8/10 step：1015/1440 loss：0.246276
[train] epoch: 8/10 step：1016/1440 loss：0.399980
[train] epoch: 8/10 step：1017/1440 loss：0.167278
[train] epoch: 8/10 step：1018/1440 loss：0.235023
[train] epoch: 8/10 step：1019/1440 loss：0.130274
[train] epoch: 8/10 step：1020/1440 loss：0.082069
[train] epoch: 8/10 step：1021/1440 loss：0.063655
[train] epoch: 8/10 step：1022/1440 loss：0.132182
[train] epoch: 8/10 step：1023/1440 loss：0.089822
[train] epoch: 8/10 step：1024/1440 loss：0.159096
[train] epoch: 8/10 step：1025/1440 loss：0.192800
[train] epoch: 8/10 step：1026/1440 loss：0.140056
[train] epoch: 8/10 step：1027/1440 loss：0.263981
[train] epoch: 8/10 step：1028/1440 loss：0.085191
[train] epoch: 8/10 step：1029/1440 loss：0.086788
[train] epoch: 8/10 step：1030/1440 loss：0.047511
[train] epoch: 8/10 step：1031/1440 loss：0.059125
[train] epoch: 8/10 step：1032/1440 loss：0.079091
[train] epoch: 8/10 step：1033/1440 loss：0.069486
[train] epoch: 8/10 step：1034/1440 loss：0.078196
[train] epoch: 8/10 step：1035/1440 loss：0.150929
[train] epoch: 8/10 step：1036/1440 loss：0.117649
[train] epoch: 8/10 step：1037/1440 loss：0.142412
[train] epoch: 8/10 step：1038/1440 loss：0.050361
[train] epoch: 8/10 step：1039/1440 loss：0.136955
[train] epoch: 8/10 step：1040/1440 loss：0.144634
[train] epoch: 8/10 step：1041/1440 loss：0.166981
[train] epoch: 8/10 step：1042/1440 loss：0.093686
[train] epoch: 8/10 step：1043/1440 loss：0.158724
[train] epoch: 8/10 step：1044/1440 loss：0.258897
[train] epoch: 8/10 step：1045/1440 loss：0.173079
[train] epoch: 8/10 step：1046/1440 loss：0.087323
[train] epoch: 8/10 step：1047/1440 loss：0.118409
[train] epoch: 8/10 step：1048/1440 loss：0.061742
[train] epoch: 8/10 step：1049/1440 loss：0.150121
[train] epoch: 8/10 step：1050/1440 loss：0.146654
[train] epoch: 8/10 step：1051/1440 loss：0.058187
[train] epoch: 8/10 step：1052/1440 loss：0.115297
[train] epoch: 8/10 step：1053/1440 loss：0.216596
[train] epoch: 8/10 step：1054/1440 loss：0.140409
[train] epoch: 8/10 step：1055/1440 loss：0.114533
[train] epoch: 8/10 step：1056/1440 loss：0.093758
[train] epoch: 8/10 step：1057/1440 loss：0.193635
[train] epoch: 8/10 step：1058/1440 loss：0.046681
[train] epoch: 8/10 step：1059/1440 loss：0.102599
[train] epoch: 8/10 step：1060/1440 loss：0.101943
[train] epoch: 8/10 step：1061/1440 loss：0.135708
[train] epoch: 8/10 step：1062/1440 loss：0.075347
[train] epoch: 8/10 step：1063/1440 loss：0.140220
[train] epoch: 8/10 step：1064/1440 loss：0.128828
[train] epoch: 8/10 step：1065/1440 loss：0.106130
[train] epoch: 8/10 step：1066/1440 loss：0.025103
[train] epoch: 8/10 step：1067/1440 loss：0.057324
[train] epoch: 8/10 step：1068/1440 loss：0.116063
[train] epoch: 8/10 step：1069/1440 loss：0.152319
[train] epoch: 8/10 step：1070/1440 loss：0.074570
[train] epoch: 8/10 step：1071/1440 loss：0.131474
[train] epoch: 8/10 step：1072/1440 loss：0.168683
[train] epoch: 8/10 step：1073/1440 loss：0.247604
[train] epoch: 8/10 step：1074/1440 loss：0.073204
[train] epoch: 8/10 step：1075/1440 loss：0.173678
[train] epoch: 8/10 step：1076/1440 loss：0.262592
[train] epoch: 8/10 step：1077/1440 loss：0.068553
[train] epoch: 8/10 step：1078/1440 loss：0.195366
[train] epoch: 8/10 step：1079/1440 loss：0.070430
[train] epoch: 8/10 step：1080/1440 loss：0.132590
[train] epoch: 8/10 step：1081/1440 loss：0.032774
[train] epoch: 8/10 step：1082/1440 loss：0.161640
[train] epoch: 8/10 step：1083/1440 loss：0.181981
[train] epoch: 8/10 step：1084/1440 loss：0.108112
[train] epoch: 8/10 step：1085/1440 loss：0.171075
[train] epoch: 8/10 step：1086/1440 loss：0.157408
[train] epoch: 8/10 step：1087/1440 loss：0.094145
[train] epoch: 8/10 step：1088/1440 loss：0.051908
[train] epoch: 8/10 step：1089/1440 loss：0.104980
[train] epoch: 8/10 step：1090/1440 loss：0.103670
[train] epoch: 8/10 step：1091/1440 loss：0.028929
[train] epoch: 8/10 step：1092/1440 loss：0.321533
[train] epoch: 8/10 step：1093/1440 loss：0.202681
[train] epoch: 8/10 step：1094/1440 loss：0.237783
[train] epoch: 8/10 step：1095/1440 loss：0.031540
[train] epoch: 8/10 step：1096/1440 loss：0.123827
[train] epoch: 8/10 step：1097/1440 loss：0.087939
[train] epoch: 8/10 step：1098/1440 loss：0.174636
[train] epoch: 8/10 step：1099/1440 loss：0.147588
[train] epoch: 8/10 step：1100/1440 loss：0.236299
[train] epoch: 8/10 step：1101/1440 loss：0.052007
[train] epoch: 8/10 step：1102/1440 loss：0.066582
[train] epoch: 8/10 step：1103/1440 loss：0.055762
[train] epoch: 8/10 step：1104/1440 loss：0.263690
[train] epoch: 8/10 step：1105/1440 loss：0.105896
[train] epoch: 8/10 step：1106/1440 loss：0.141342
[train] epoch: 8/10 step：1107/1440 loss：0.188313
[train] epoch: 8/10 step：1108/1440 loss：0.167265
[train] epoch: 8/10 step：1109/1440 loss：0.134631
[train] epoch: 8/10 step：1110/1440 loss：0.149404
[train] epoch: 8/10 step：1111/1440 loss：0.064469
[train] epoch: 8/10 step：1112/1440 loss：0.164338
[train] epoch: 8/10 step：1113/1440 loss：0.168012
[train] epoch: 8/10 step：1114/1440 loss：0.156826
[train] epoch: 8/10 step：1115/1440 loss：0.094151
[train] epoch: 8/10 step：1116/1440 loss：0.086337
[train] epoch: 8/10 step：1117/1440 loss：0.016054
[train] epoch: 8/10 step：1118/1440 loss：0.140627
[train] epoch: 8/10 step：1119/1440 loss：0.175835
[train] epoch: 8/10 step：1120/1440 loss：0.084117
[train] epoch: 8/10 step：1121/1440 loss：0.194448
[train] epoch: 8/10 step：1122/1440 loss：0.214029
[train] epoch: 8/10 step：1123/1440 loss：0.264691
[train] epoch: 8/10 step：1124/1440 loss：0.051324
[train] epoch: 8/10 step：1125/1440 loss：0.075292
[train] epoch: 8/10 step：1126/1440 loss：0.173578
[train] epoch: 8/10 step：1127/1440 loss：0.283253
[train] epoch: 8/10 step：1128/1440 loss：0.130344
[train] epoch: 8/10 step：1129/1440 loss：0.127743
[train] epoch: 8/10 step：1130/1440 loss：0.193382
[train] epoch: 8/10 step：1131/1440 loss：0.136850
[train] epoch: 8/10 step：1132/1440 loss：0.084361
[train] epoch: 8/10 step：1133/1440 loss：0.057523
[train] epoch: 8/10 step：1134/1440 loss：0.123670
[train] epoch: 8/10 step：1135/1440 loss：0.149448
[train] epoch: 8/10 step：1136/1440 loss：0.070096
[train] epoch: 8/10 step：1137/1440 loss：0.179513
[train] epoch: 8/10 step：1138/1440 loss：0.179169
[train] epoch: 8/10 step：1139/1440 loss：0.203196
[train] epoch: 8/10 step：1140/1440 loss：0.118047
[train] epoch: 8/10 step：1141/1440 loss：0.076637
[train] epoch: 8/10 step：1142/1440 loss：0.084829
[train] epoch: 8/10 step：1143/1440 loss：0.129453
[train] epoch: 8/10 step：1144/1440 loss：0.102871
[train] epoch: 8/10 step：1145/1440 loss：0.074677
[train] epoch: 8/10 step：1146/1440 loss：0.105892
[train] epoch: 8/10 step：1147/1440 loss：0.168798
[train] epoch: 8/10 step：1148/1440 loss：0.067033
[train] epoch: 8/10 step：1149/1440 loss：0.191140
[train] epoch: 8/10 step：1150/1440 loss：0.073604
[train] epoch: 8/10 step：1151/1440 loss：0.096911
[train] epoch: 8/10 step：1152/1440 loss：0.280165
[train] epoch: 9/10 step：1153/1440 loss：0.123344
[train] epoch: 9/10 step：1154/1440 loss：0.260750
[train] epoch: 9/10 step：1155/1440 loss：0.076548
[train] epoch: 9/10 step：1156/1440 loss：0.199794
[train] epoch: 9/10 step：1157/1440 loss：0.071992
[train] epoch: 9/10 step：1158/1440 loss：0.091153
[train] epoch: 9/10 step：1159/1440 loss：0.098993
[train] epoch: 9/10 step：1160/1440 loss：0.067917
[train] epoch: 9/10 step：1161/1440 loss：0.050300
[train] epoch: 9/10 step：1162/1440 loss：0.032854
[train] epoch: 9/10 step：1163/1440 loss：0.021810
[train] epoch: 9/10 step：1164/1440 loss：0.079908
[train] epoch: 9/10 step：1165/1440 loss：0.207096
[train] epoch: 9/10 step：1166/1440 loss：0.127126
[train] epoch: 9/10 step：1167/1440 loss：0.134195
[train] epoch: 9/10 step：1168/1440 loss：0.122964
[train] epoch: 9/10 step：1169/1440 loss：0.120619
[train] epoch: 9/10 step：1170/1440 loss：0.180244
[train] epoch: 9/10 step：1171/1440 loss：0.040850
[train] epoch: 9/10 step：1172/1440 loss：0.220960
[train] epoch: 9/10 step：1173/1440 loss：0.165228
[train] epoch: 9/10 step：1174/1440 loss：0.261682
[train] epoch: 9/10 step：1175/1440 loss：0.113378
[train] epoch: 9/10 step：1176/1440 loss：0.028469
[train] epoch: 9/10 step：1177/1440 loss：0.154004
[train] epoch: 9/10 step：1178/1440 loss：0.147391
[train] epoch: 9/10 step：1179/1440 loss：0.080827
[train] epoch: 9/10 step：1180/1440 loss：0.077106
[train] epoch: 9/10 step：1181/1440 loss：0.124518
[train] epoch: 9/10 step：1182/1440 loss：0.159878
[train] epoch: 9/10 step：1183/1440 loss：0.136695
[train] epoch: 9/10 step：1184/1440 loss：0.046558
[train] epoch: 9/10 step：1185/1440 loss：0.102413
[train] epoch: 9/10 step：1186/1440 loss：0.079436
[train] epoch: 9/10 step：1187/1440 loss：0.052533
[train] epoch: 9/10 step：1188/1440 loss：0.211310
[train] epoch: 9/10 step：1189/1440 loss：0.071666
[train] epoch: 9/10 step：1190/1440 loss：0.076443
[train] epoch: 9/10 step：1191/1440 loss：0.058207
[train] epoch: 9/10 step：1192/1440 loss：0.212168
[train] epoch: 9/10 step：1193/1440 loss：0.239030
[train] epoch: 9/10 step：1194/1440 loss：0.065417
[train] epoch: 9/10 step：1195/1440 loss：0.120138
[train] epoch: 9/10 step：1196/1440 loss：0.047739
[train] epoch: 9/10 step：1197/1440 loss：0.145533
[train] epoch: 9/10 step：1198/1440 loss：0.091051
[train] epoch: 9/10 step：1199/1440 loss：0.123595
[train] epoch: 9/10 step：1200/1440 loss：0.057506
[train] epoch: 9/10 step：1201/1440 loss：0.041975
[train] epoch: 9/10 step：1202/1440 loss：0.045599
[train] epoch: 9/10 step：1203/1440 loss：0.160876
[train] epoch: 9/10 step：1204/1440 loss：0.080766
[train] epoch: 9/10 step：1205/1440 loss：0.308966
[train] epoch: 9/10 step：1206/1440 loss：0.070548
[train] epoch: 9/10 step：1207/1440 loss：0.100621
[train] epoch: 9/10 step：1208/1440 loss：0.108842
[train] epoch: 9/10 step：1209/1440 loss：0.085839
[train] epoch: 9/10 step：1210/1440 loss：0.113318
[train] epoch: 9/10 step：1211/1440 loss：0.057264
[train] epoch: 9/10 step：1212/1440 loss：0.123804
[train] epoch: 9/10 step：1213/1440 loss：0.128913
[train] epoch: 9/10 step：1214/1440 loss：0.110596
[train] epoch: 9/10 step：1215/1440 loss：0.245693
[train] epoch: 9/10 step：1216/1440 loss：0.021967
[train] epoch: 9/10 step：1217/1440 loss：0.022176
[train] epoch: 9/10 step：1218/1440 loss：0.061088
[train] epoch: 9/10 step：1219/1440 loss：0.068549
[train] epoch: 9/10 step：1220/1440 loss：0.065604
[train] epoch: 9/10 step：1221/1440 loss：0.128390
[train] epoch: 9/10 step：1222/1440 loss：0.042216
[train] epoch: 9/10 step：1223/1440 loss：0.053451
[train] epoch: 9/10 step：1224/1440 loss：0.111021
[train] epoch: 9/10 step：1225/1440 loss：0.062210
[train] epoch: 9/10 step：1226/1440 loss：0.118937
[train] epoch: 9/10 step：1227/1440 loss：0.089035
[train] epoch: 9/10 step：1228/1440 loss：0.196140
[train] epoch: 9/10 step：1229/1440 loss：0.038820
[train] epoch: 9/10 step：1230/1440 loss：0.054284
[train] epoch: 9/10 step：1231/1440 loss：0.049342
[train] epoch: 9/10 step：1232/1440 loss：0.182932
[train] epoch: 9/10 step：1233/1440 loss：0.128974
[train] epoch: 9/10 step：1234/1440 loss：0.081719
[train] epoch: 9/10 step：1235/1440 loss：0.068358
[train] epoch: 9/10 step：1236/1440 loss：0.098559
[train] epoch: 9/10 step：1237/1440 loss：0.076116
[train] epoch: 9/10 step：1238/1440 loss：0.105869
[train] epoch: 9/10 step：1239/1440 loss：0.113616
[train] epoch: 9/10 step：1240/1440 loss：0.030090
[train] epoch: 9/10 step：1241/1440 loss：0.064365
[train] epoch: 9/10 step：1242/1440 loss：0.108079
[train] epoch: 9/10 step：1243/1440 loss：0.090546
[train] epoch: 9/10 step：1244/1440 loss：0.077126
[train] epoch: 9/10 step：1245/1440 loss：0.093734
[train] epoch: 9/10 step：1246/1440 loss：0.028295
[train] epoch: 9/10 step：1247/1440 loss：0.121794
[train] epoch: 9/10 step：1248/1440 loss：0.044067
[train] epoch: 9/10 step：1249/1440 loss：0.142269
[train] epoch: 9/10 step：1250/1440 loss：0.054370
[train] epoch: 9/10 step：1251/1440 loss：0.254625
[train] epoch: 9/10 step：1252/1440 loss：0.221043
[train] epoch: 9/10 step：1253/1440 loss：0.197599
[train] epoch: 9/10 step：1254/1440 loss：0.078679
[train] epoch: 9/10 step：1255/1440 loss：0.064218
[train] epoch: 9/10 step：1256/1440 loss：0.144172
[train] epoch: 9/10 step：1257/1440 loss：0.086305
[train] epoch: 9/10 step：1258/1440 loss：0.167062
[train] epoch: 9/10 step：1259/1440 loss：0.095425
[train] epoch: 9/10 step：1260/1440 loss：0.143404
[train] epoch: 9/10 step：1261/1440 loss：0.118747
[train] epoch: 9/10 step：1262/1440 loss：0.094415
[train] epoch: 9/10 step：1263/1440 loss：0.016406
[train] epoch: 9/10 step：1264/1440 loss：0.118711
[train] epoch: 9/10 step：1265/1440 loss：0.120098
[train] epoch: 9/10 step：1266/1440 loss：0.024742
[train] epoch: 9/10 step：1267/1440 loss：0.063232
[train] epoch: 9/10 step：1268/1440 loss：0.134965
[train] epoch: 9/10 step：1269/1440 loss：0.170564
[train] epoch: 9/10 step：1270/1440 loss：0.102316
[train] epoch: 9/10 step：1271/1440 loss：0.353599
[train] epoch: 9/10 step：1272/1440 loss：0.085922
[train] epoch: 9/10 step：1273/1440 loss：0.099745
[train] epoch: 9/10 step：1274/1440 loss：0.364181
[train] epoch: 9/10 step：1275/1440 loss：0.086048
[train] epoch: 9/10 step：1276/1440 loss：0.046182
[train] epoch: 9/10 step：1277/1440 loss：0.172183
[train] epoch: 9/10 step：1278/1440 loss：0.056542
[train] epoch: 9/10 step：1279/1440 loss：0.080239
[train] epoch: 9/10 step：1280/1440 loss：0.035988
[train] epoch: 9/10 step：1281/1440 loss：0.070159
[train] epoch: 9/10 step：1282/1440 loss：0.222377
[train] epoch: 9/10 step：1283/1440 loss：0.165677
[train] epoch: 9/10 step：1284/1440 loss：0.163440
[train] epoch: 9/10 step：1285/1440 loss：0.188475
[train] epoch: 9/10 step：1286/1440 loss：0.137583
[train] epoch: 9/10 step：1287/1440 loss：0.097645
[train] epoch: 9/10 step：1288/1440 loss：0.029295
[train] epoch: 9/10 step：1289/1440 loss：0.032749
[train] epoch: 9/10 step：1290/1440 loss：0.354031
[train] epoch: 9/10 step：1291/1440 loss：0.330858
[train] epoch: 9/10 step：1292/1440 loss：0.086826
[train] epoch: 9/10 step：1293/1440 loss：0.046164
[train] epoch: 9/10 step：1294/1440 loss：0.235814
[train] epoch: 9/10 step：1295/1440 loss：0.141050
[train] epoch: 9/10 step：1296/1440 loss：0.101096
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at model/chinese-bert-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[train] epoch: 10/10 step：1297/1440 loss：0.049112
[train] epoch: 10/10 step：1298/1440 loss：0.112599
[train] epoch: 10/10 step：1299/1440 loss：0.017638
[train] epoch: 10/10 step：1300/1440 loss：0.134945
[train] epoch: 10/10 step：1301/1440 loss：0.061317
[train] epoch: 10/10 step：1302/1440 loss：0.080201
[train] epoch: 10/10 step：1303/1440 loss：0.044876
[train] epoch: 10/10 step：1304/1440 loss：0.062872
[train] epoch: 10/10 step：1305/1440 loss：0.097684
[train] epoch: 10/10 step：1306/1440 loss：0.173411
[train] epoch: 10/10 step：1307/1440 loss：0.222816
[train] epoch: 10/10 step：1308/1440 loss：0.053734
[train] epoch: 10/10 step：1309/1440 loss：0.203517
[train] epoch: 10/10 step：1310/1440 loss：0.093951
[train] epoch: 10/10 step：1311/1440 loss：0.159778
[train] epoch: 10/10 step：1312/1440 loss：0.076693
[train] epoch: 10/10 step：1313/1440 loss：0.077492
[train] epoch: 10/10 step：1314/1440 loss：0.134041
[train] epoch: 10/10 step：1315/1440 loss：0.167708
[train] epoch: 10/10 step：1316/1440 loss：0.146467
[train] epoch: 10/10 step：1317/1440 loss：0.190148
[train] epoch: 10/10 step：1318/1440 loss：0.049786
[train] epoch: 10/10 step：1319/1440 loss：0.132543
[train] epoch: 10/10 step：1320/1440 loss：0.078926
[train] epoch: 10/10 step：1321/1440 loss：0.122672
[train] epoch: 10/10 step：1322/1440 loss：0.040985
[train] epoch: 10/10 step：1323/1440 loss：0.119378
[train] epoch: 10/10 step：1324/1440 loss：0.150000
[train] epoch: 10/10 step：1325/1440 loss：0.136026
[train] epoch: 10/10 step：1326/1440 loss：0.048947
[train] epoch: 10/10 step：1327/1440 loss：0.021887
[train] epoch: 10/10 step：1328/1440 loss：0.023429
[train] epoch: 10/10 step：1329/1440 loss：0.099001
[train] epoch: 10/10 step：1330/1440 loss：0.072742
[train] epoch: 10/10 step：1331/1440 loss：0.016542
[train] epoch: 10/10 step：1332/1440 loss：0.094417
[train] epoch: 10/10 step：1333/1440 loss：0.077029
[train] epoch: 10/10 step：1334/1440 loss：0.048672
[train] epoch: 10/10 step：1335/1440 loss：0.131737
[train] epoch: 10/10 step：1336/1440 loss：0.012839
[train] epoch: 10/10 step：1337/1440 loss：0.058638
[train] epoch: 10/10 step：1338/1440 loss：0.052397
[train] epoch: 10/10 step：1339/1440 loss：0.063392
[train] epoch: 10/10 step：1340/1440 loss：0.197357
[train] epoch: 10/10 step：1341/1440 loss：0.253969
[train] epoch: 10/10 step：1342/1440 loss：0.061607
[train] epoch: 10/10 step：1343/1440 loss：0.133226
[train] epoch: 10/10 step：1344/1440 loss：0.067601
[train] epoch: 10/10 step：1345/1440 loss：0.157071
[train] epoch: 10/10 step：1346/1440 loss：0.020174
[train] epoch: 10/10 step：1347/1440 loss：0.130516
[train] epoch: 10/10 step：1348/1440 loss：0.095940
[train] epoch: 10/10 step：1349/1440 loss：0.156157
[train] epoch: 10/10 step：1350/1440 loss：0.093950
[train] epoch: 10/10 step：1351/1440 loss：0.054289
[train] epoch: 10/10 step：1352/1440 loss：0.101531
[train] epoch: 10/10 step：1353/1440 loss：0.038027
[train] epoch: 10/10 step：1354/1440 loss：0.088665
[train] epoch: 10/10 step：1355/1440 loss：0.068018
[train] epoch: 10/10 step：1356/1440 loss：0.081840
[train] epoch: 10/10 step：1357/1440 loss：0.025863
[train] epoch: 10/10 step：1358/1440 loss：0.037121
[train] epoch: 10/10 step：1359/1440 loss：0.094607
[train] epoch: 10/10 step：1360/1440 loss：0.051062
[train] epoch: 10/10 step：1361/1440 loss：0.231009
[train] epoch: 10/10 step：1362/1440 loss：0.014254
[train] epoch: 10/10 step：1363/1440 loss：0.008249
[train] epoch: 10/10 step：1364/1440 loss：0.114483
[train] epoch: 10/10 step：1365/1440 loss：0.059741
[train] epoch: 10/10 step：1366/1440 loss：0.036106
[train] epoch: 10/10 step：1367/1440 loss：0.194177
[train] epoch: 10/10 step：1368/1440 loss：0.052602
[train] epoch: 10/10 step：1369/1440 loss：0.065434
[train] epoch: 10/10 step：1370/1440 loss：0.031685
[train] epoch: 10/10 step：1371/1440 loss：0.072289
[train] epoch: 10/10 step：1372/1440 loss：0.161894
[train] epoch: 10/10 step：1373/1440 loss：0.084594
[train] epoch: 10/10 step：1374/1440 loss：0.066924
[train] epoch: 10/10 step：1375/1440 loss：0.247555
[train] epoch: 10/10 step：1376/1440 loss：0.232925
[train] epoch: 10/10 step：1377/1440 loss：0.194286
[train] epoch: 10/10 step：1378/1440 loss：0.058657
[train] epoch: 10/10 step：1379/1440 loss：0.018036
[train] epoch: 10/10 step：1380/1440 loss：0.066797
[train] epoch: 10/10 step：1381/1440 loss：0.140171
[train] epoch: 10/10 step：1382/1440 loss：0.064383
[train] epoch: 10/10 step：1383/1440 loss：0.075625
[train] epoch: 10/10 step：1384/1440 loss：0.013053
[train] epoch: 10/10 step：1385/1440 loss：0.132489
[train] epoch: 10/10 step：1386/1440 loss：0.042232
[train] epoch: 10/10 step：1387/1440 loss：0.045402
[train] epoch: 10/10 step：1388/1440 loss：0.165234
[train] epoch: 10/10 step：1389/1440 loss：0.161820
[train] epoch: 10/10 step：1390/1440 loss：0.173106
[train] epoch: 10/10 step：1391/1440 loss：0.066184
[train] epoch: 10/10 step：1392/1440 loss：0.019205
[train] epoch: 10/10 step：1393/1440 loss：0.079115
[train] epoch: 10/10 step：1394/1440 loss：0.062569
[train] epoch: 10/10 step：1395/1440 loss：0.167899
[train] epoch: 10/10 step：1396/1440 loss：0.103963
[train] epoch: 10/10 step：1397/1440 loss：0.121486
[train] epoch: 10/10 step：1398/1440 loss：0.037624
[train] epoch: 10/10 step：1399/1440 loss：0.031007
[train] epoch: 10/10 step：1400/1440 loss：0.101054
[train] epoch: 10/10 step：1401/1440 loss：0.279300
[train] epoch: 10/10 step：1402/1440 loss：0.163730
[train] epoch: 10/10 step：1403/1440 loss：0.039313
[train] epoch: 10/10 step：1404/1440 loss：0.104974
[train] epoch: 10/10 step：1405/1440 loss：0.071888
[train] epoch: 10/10 step：1406/1440 loss：0.112068
[train] epoch: 10/10 step：1407/1440 loss：0.047291
[train] epoch: 10/10 step：1408/1440 loss：0.031519
[train] epoch: 10/10 step：1409/1440 loss：0.067359
[train] epoch: 10/10 step：1410/1440 loss：0.049958
[train] epoch: 10/10 step：1411/1440 loss：0.097962
[train] epoch: 10/10 step：1412/1440 loss：0.047558
[train] epoch: 10/10 step：1413/1440 loss：0.076436
[train] epoch: 10/10 step：1414/1440 loss：0.091801
[train] epoch: 10/10 step：1415/1440 loss：0.166011
[train] epoch: 10/10 step：1416/1440 loss：0.069617
[train] epoch: 10/10 step：1417/1440 loss：0.179201
[train] epoch: 10/10 step：1418/1440 loss：0.085653
[train] epoch: 10/10 step：1419/1440 loss：0.080134
[train] epoch: 10/10 step：1420/1440 loss：0.102191
[train] epoch: 10/10 step：1421/1440 loss：0.084583
[train] epoch: 10/10 step：1422/1440 loss：0.088740
[train] epoch: 10/10 step：1423/1440 loss：0.043568
[train] epoch: 10/10 step：1424/1440 loss：0.316119
[train] epoch: 10/10 step：1425/1440 loss：0.096030
[train] epoch: 10/10 step：1426/1440 loss：0.104616
[train] epoch: 10/10 step：1427/1440 loss：0.085467
[train] epoch: 10/10 step：1428/1440 loss：0.056794
[train] epoch: 10/10 step：1429/1440 loss：0.087189
[train] epoch: 10/10 step：1430/1440 loss：0.114121
[train] epoch: 10/10 step：1431/1440 loss：0.123600
[train] epoch: 10/10 step：1432/1440 loss：0.088220
[train] epoch: 10/10 step：1433/1440 loss：0.035611
[train] epoch: 10/10 step：1434/1440 loss：0.164366
[train] epoch: 10/10 step：1435/1440 loss：0.076305
[train] epoch: 10/10 step：1436/1440 loss：0.063385
[train] epoch: 10/10 step：1437/1440 loss：0.147040
[train] epoch: 10/10 step：1438/1440 loss：0.143751
[train] epoch: 10/10 step：1439/1440 loss：0.110296
[train] epoch: 10/10 step：1440/1440 loss：0.013748
耗时：119.474534034729秒
(800,) (800,)
              precision    recall  f1-score   support

          其他       0.69      0.61      0.64       291
          喜好       0.55      0.65      0.60       133
          悲伤       0.50      0.57      0.53       102
          厌恶       0.37      0.41      0.39       113
          愤怒       0.48      0.37      0.42        60
          高兴       0.60      0.58      0.59       101

    accuracy                           0.56       800
   macro avg       0.53      0.53      0.53       800
weighted avg       0.57      0.56      0.56       800

===============end=====================

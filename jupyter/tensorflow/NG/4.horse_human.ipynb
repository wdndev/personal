{
 "cells": [
  {
   "source": [
    "#### 解压数据集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method ZipFile.close of <zipfile.ZipFile filename='E:/02Studying/03DeepLearning/dataset/validation-horse-or-human.zip' mode='r'>>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = 'E:/02Studying/03DeepLearning/dataset/horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/horse-or-human')\n",
    "local_zip = 'E:/02Studying/03DeepLearning/dataset/validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/validation-horse-or-human')\n",
    "zip_ref.close"
   ]
  },
  {
   "source": [
    "#### 划分数据集为训练集和验证集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse_dir = os.path.join('E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/horse-or-human/horses')\n",
    "train_hunman_dir = os.path.join('E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/horse-or-human/humans')\n",
    "\n",
    "val_horse_dir = os.path.join('E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/validation-horse-or-human/horses')\n",
    "val_human_dir = os.path.join('E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/validation-horse-or-human/humans')"
   ]
  },
  {
   "source": [
    "#### 打印部分训练集和验证集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['horse01-0.png', 'horse01-1.png', 'horse01-2.png', 'horse01-3.png', 'horse01-4.png', 'horse01-5.png', 'horse01-6.png', 'horse01-7.png', 'horse01-8.png', 'horse01-9.png']\n['human01-00.png', 'human01-01.png', 'human01-02.png', 'human01-03.png', 'human01-04.png', 'human01-05.png', 'human01-06.png', 'human01-07.png', 'human01-08.png', 'human01-09.png']\n['horse1-000.png', 'horse1-105.png', 'horse1-122.png', 'horse1-127.png', 'horse1-170.png', 'horse1-204.png', 'horse1-224.png', 'horse1-241.png', 'horse1-264.png', 'horse1-276.png']\n['valhuman01-00.png', 'valhuman01-01.png', 'valhuman01-02.png', 'valhuman01-03.png', 'valhuman01-04.png', 'valhuman01-05.png', 'valhuman01-06.png', 'valhuman01-07.png', 'valhuman01-08.png', 'valhuman01-09.png']\n"
     ]
    }
   ],
   "source": [
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "\n",
    "train_human_names = os.listdir(train_hunman_dir)\n",
    "print(train_human_names[:10])\n",
    "\n",
    "val_horse_names = os.listdir(val_horse_dir)\n",
    "print(val_horse_names[:10])\n",
    "\n",
    "val_human_names = os.listdir(val_human_dir)\n",
    "print(val_human_names[:10])"
   ]
  },
  {
   "source": [
    "#### 输出训练集和验证集的数量"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total training horse images:  500\ntotal training human images:  527\ntotal val horse images:  128\ntotal val human images:  128\n"
     ]
    }
   ],
   "source": [
    "print('total training horse images: ', len(os.listdir(train_horse_dir)))\n",
    "print('total training human images: ', len(os.listdir(train_hunman_dir)))\n",
    "print('total val horse images: ', len(os.listdir(val_horse_dir)))\n",
    "print('total val human images: ', len(os.listdir(val_human_dir)))"
   ]
  },
  {
   "source": [
    "#### 构建模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "source": [
    "#### 输出搭建的模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 148, 148, 16)      448       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 18496)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               9470464   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 9,494,561\nTrainable params: 9,494,561\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "source": [
    "#### 设置模型的优化器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "source": [
    "#### 生成训练集和验证集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1027 images belonging to 2 classes.\nFound 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/horse-or-human',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/validation-horse-or-human',\n",
    "    target_size=(150,150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "source": [
    "#### 开始训练"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-5dc33069a5f1>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 4s 502ms/step - loss: 1.8029 - acc: 0.4980 - val_loss: 0.5430 - val_acc: 0.6992\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.6278 - acc: 0.6452 - val_loss: 0.5152 - val_acc: 0.7539\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 0.9082 - acc: 0.7486 - val_loss: 1.1273 - val_acc: 0.6172\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.3877 - acc: 0.8242 - val_loss: 0.7536 - val_acc: 0.8242\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 4s 470ms/step - loss: 0.1815 - acc: 0.9277 - val_loss: 1.3637 - val_acc: 0.7461\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.0977 - acc: 0.9588 - val_loss: 0.9615 - val_acc: 0.8398\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 0.0511 - acc: 0.9822 - val_loss: 0.4929 - val_acc: 0.9023\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.4638 - acc: 0.8565 - val_loss: 1.3596 - val_acc: 0.7969\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 4s 536ms/step - loss: 0.0649 - acc: 0.9722 - val_loss: 1.5928 - val_acc: 0.7734\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 4s 472ms/step - loss: 0.0200 - acc: 0.9944 - val_loss: 1.5423 - val_acc: 0.8281\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.0081 - acc: 0.9989 - val_loss: 1.3528 - val_acc: 0.8633\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.4500 - acc: 0.8287 - val_loss: 0.6271 - val_acc: 0.8555\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 4s 477ms/step - loss: 0.0360 - acc: 0.9933 - val_loss: 1.5951 - val_acc: 0.8320\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 1.6455 - val_acc: 0.8398\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 4s 468ms/step - loss: 0.1131 - acc: 0.9677 - val_loss: 0.6723 - val_acc: 0.8555\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,  \n",
    "      epochs=15,\n",
    "      verbose=1,\n",
    "      validation_data = val_generator,\n",
    "      validation_steps=8\n",
    "      )"
   ]
  },
  {
   "source": [
    "#### 测试训练的模型效果"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.]\nE:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/test-horse-or-human\\hor1.jpg is a human\n[0.]\nE:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/test-horse-or-human\\hor2.jpg is a horse\n[1.]\nE:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/test-horse-or-human\\hor3.jpg is a human\n[1.]\nE:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/test-horse-or-human\\hor4.jpg is a human\n[1.]\nE:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/test-horse-or-human\\hum1.jpg is a human\n[1.]\nE:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/test-horse-or-human\\hum2.jpg is a human\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "\n",
    "image_dir = 'E:/02Studying/03DeepLearning/dataset/jupyter/04horse_human/test-horse-or-human'\n",
    "\n",
    "image_names = os.listdir(image_dir)\n",
    "sorted_image_names = sorted(image_names)\n",
    "for name in sorted_image_names:\n",
    "    image_name = os.path.join(image_dir, name)\n",
    "    image = cv2.imread(image_name)\n",
    "\n",
    "    x = cv2.resize(image, (150, 150))\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    "\n",
    "#     path = '/content' + fn\n",
    "#     img = image.load_img(path, target_size=(150,150))\n",
    "#     x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=20)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(image_name + \" is a human\")\n",
    "    else:\n",
    "        print(image_name + \" is a horse\")\n"
   ]
  },
  {
   "source": [
    "#### 清除内存"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2773ec50bb94a4c56ca70fdf51a3b4a311790b3b473abe6162edfc2060bd37dd"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}